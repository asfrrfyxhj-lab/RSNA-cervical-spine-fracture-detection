import os
import numpy as np
import torch
from torch.utils.data import Dataset
import albumentations as A
from albumentations.pytorch import ToTensorV2
from tqdm import tqdm



class CervicalDataset(Dataset):
    def __init__(self, patient_list_file, data_dir, transform=None, cache_to_ram=True):
        with open(patient_list_file, 'r') as f:
            self.patient_ids = [line.strip() for line in f.readlines()]
        
        self.data_dir = data_dir
        self.transform = transform
        self.cache_to_ram = cache_to_ram
        self.num_slices = 128
        
        self.image_cache = {}
        self.mask_cache = {}

        if self.cache_to_ram:
            print(f"ğŸ§  {patient_list_file} ë°ì´í„°ë¥¼ RAMì— ë¡œë”© ì¤‘...")
            for pid in tqdm(self.patient_ids):
                img = np.load(os.path.join(data_dir, f"{pid}_img.npy")).astype(np.float32)
                mask = np.load(os.path.join(data_dir, f"{pid}_mask.npy")).astype(np.uint8)
                # ë¼ë²¨ 8(T1), 9(T2)ëŠ” ë°°ê²½(0)ìœ¼ë¡œ ë°€ê¸°
                mask = np.where(mask > 7, 0, mask)
                
                self.image_cache[pid] = img
                self.mask_cache[pid] = mask
            print(f"âœ… ë¡œë”© ì™„ë£Œ!")

    def __len__(self):
        return len(self.patient_ids) * self.num_slices

    def __getitem__(self, idx):
        patient_idx = idx // self.num_slices
        slice_idx = idx % self.num_slices
        pid = self.patient_ids[patient_idx]

        # 1. ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        if self.cache_to_ram:
            image = self.image_cache[pid][slice_idx]
            mask = self.mask_cache[pid][slice_idx]
        else:
            image = np.load(os.path.join(self.data_dir, f"{pid}_img.npy"))[slice_idx]
            mask = np.load(os.path.join(self.data_dir, f"{pid}_mask.npy"))[slice_idx]
            # [Fix] ìºì‹± ì•ˆ í•  ë•Œë„ ë¼ë²¨ ì •ë¦¬ê°€ í•„ìš”í•¨
            mask = np.where(mask > 7, 0, mask).astype(np.uint8)

        # 2. Augmentation (image: H, W / mask: H, W)
        if self.transform:
            augmented = self.transform(image=image, mask=mask)
            image = augmented['image'] # (1, 224, 224) í…ì„œ
            mask = augmented['mask']   # (224, 224) í…ì„œ
        else:
            # transformì´ ì—†ì„ ê²½ìš°ë¥¼ ëŒ€ë¹„í•œ ê¸°ë³¸ í…ì„œí™”
            image = torch.from_numpy(image).unsqueeze(0) # (1, 224, 224)
            mask = torch.from_numpy(mask).long()

        # 3. Z-position ì±„ë„ ì¶”ê°€ (0 ~ 1)
        z_pos = slice_idx / (self.num_slices - 1)
        # image.shape[1:]ë¥¼ ì¨ì„œ H, W í¬ê¸°ë§Œ ê°€ì ¸ì™€ 2D í‰ë©´ ìƒì„±
        z_channel = np.full(image.shape[1:], z_pos, dtype=np.float32)
        z_tensor = torch.from_numpy(z_channel).unsqueeze(0) # (1, 224, 224)
        
        # 4. ì±„ë„ ê²°í•© (Image + Z) -> (2, 224, 224)
        image = torch.cat([image, z_tensor], dim=0)

        # ë§ˆìŠ¤í¬ íƒ€ì… ë³´ì •
        if not isinstance(mask, torch.Tensor):
            mask = torch.from_numpy(mask)
        mask = mask.long()

        return image, mask

# --- ë°ì´í„° ì¦ê°•(Augmentation) ì •ì˜ ì˜ˆì‹œ ---
def get_transforms(mode='train'):
    if mode == 'train':
        return A.Compose([
            A.HorizontalFlip(p=0.5),      # 50% í™•ë¥ ë¡œ ì¢Œìš° ë°˜ì „
            A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=15, p=0.5), # ë¯¸ì„¸í•œ íšŒì „/ì´ë™
            A.RandomBrightnessContrast(p=0.2), # ë°ê¸° ì¡°ì ˆ
            # NormalizeëŠ” ëª¨ë¸ì˜ pre-trained ê°€ì¤‘ì¹˜ì— ë”°ë¼ ê²°ì • (ê¸°ë³¸ì€ ToTensorV2)
            ToTensorV2()
        ])
    else:
        # ê²€ì¦(Val) ì‹œì—ëŠ” ì¦ê°• ì—†ì´ í…ì„œ ë³€í™˜ë§Œ
        return A.Compose([
            ToTensorV2()
        ])
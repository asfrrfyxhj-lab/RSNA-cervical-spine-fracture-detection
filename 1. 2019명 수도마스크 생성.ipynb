{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ec48a5c",
   "metadata": {},
   "source": [
    "## ìˆ˜ë„ ë§ˆìŠ¤í¬ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7dfd1cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ 5-Fold Seg ëª¨ë¸ ê°€ì¤‘ì¹˜ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...\n",
      "âœ… 5-Fold ëª¨ë¸ ì•™ìƒë¸” ì¤€ë¹„ ì™„ë£Œ\n",
      "\n",
      "ğŸ“¦ ì „ì²´ í™˜ì: 2019ëª…\n",
      "âœ… ì´ë¯¸ ë§ˆìŠ¤í¬ê°€ ìˆëŠ” í™˜ì: 1328ëª…\n",
      "ğŸ”¥ ìƒˆë¡œ ë§Œë“¤ì–´ì•¼ í•  í™˜ì: 691ëª…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Missing Masks: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 691/691 [1:16:35<00:00,  6.65s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pydicom\n",
    "import SimpleITK as sitk\n",
    "from scipy.ndimage import zoom\n",
    "from tqdm import tqdm\n",
    "import segmentation_models_pytorch as smp\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# --- [1. ê²½ë¡œ ë° ì„¤ì •] ---\n",
    "TRAIN_IMAGES_DIR = r'C:\\conda\\3. Project\\rsna-2022-cervical-spine-fracture-detection\\old_train\\train_images'\n",
    "WEIGHTS_DIR = r'C:\\conda\\3. Project\\rsna-2022-cervical-spine-fracture-detection\\golden_dataset\\checkpoints' \n",
    "MASK_SAVE_ROOT = r'C:\\conda\\3. Project\\rsna-2022-cervical-spine-fracture-detection\\old_train\\pseudo_segmentation_masks_2019'\n",
    "\n",
    "TARGET_Z, TARGET_SIZE = 128, 224\n",
    "WL, WW = 500, 2000\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "os.makedirs(MASK_SAVE_ROOT, exist_ok=True)\n",
    "\n",
    "# --- [2. ëª¨ë¸ 5ê°œ ë¡œë“œ] ---\n",
    "models = []\n",
    "print(\"ğŸ”„ 5-Fold Seg ëª¨ë¸ ê°€ì¤‘ì¹˜ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...\")\n",
    "for f in range(1, 6):\n",
    "    model_path = os.path.join(WEIGHTS_DIR, f'best_model_fold{f}.pth')\n",
    "    m = smp.Unet(encoder_name=\"resnet34\", in_channels=2, classes=8).to(DEVICE)\n",
    "    m.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
    "    m.eval()\n",
    "    models.append(m)\n",
    "print(f\"âœ… 5-Fold ëª¨ë¸ ì•™ìƒë¸” ì¤€ë¹„ ì™„ë£Œ\")\n",
    "\n",
    "# --- [3. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜] ---\n",
    "def apply_windowing(img, wl, ww):\n",
    "    img_min, img_max = wl - ww // 2, wl + ww // 2\n",
    "    img = np.clip(img, img_min, img_max)\n",
    "    return ((img - img_min) / ww).astype(np.float32)\n",
    "\n",
    "# --- [4. ë¹µê¾¸ë‚œ ë§ˆìŠ¤í¬ ì±„ìš°ê¸° ë£¨í”„] ---\n",
    "@torch.no_grad()\n",
    "def run_ensemble_factory_fill_missing():\n",
    "    all_uids = [d for d in os.listdir(TRAIN_IMAGES_DIR) if os.path.isdir(os.path.join(TRAIN_IMAGES_DIR, d))]\n",
    "    \n",
    "    # ğŸ¯ [í•µì‹¬] ë£¨í”„ë¥¼ ëŒê¸° ì „ì—, ë§ˆìŠ¤í¬ê°€ ì—†ëŠ” í™˜ìë§Œ ë¯¸ë¦¬ ê³¨ë¼ëƒ…ë‹ˆë‹¤!\n",
    "    missing_uids = []\n",
    "    for uid in all_uids:\n",
    "        if not os.path.exists(os.path.join(MASK_SAVE_ROOT, f\"{uid}.nii.gz\")):\n",
    "            missing_uids.append(uid)\n",
    "\n",
    "    print(f\"\\nğŸ“¦ ì „ì²´ í™˜ì: {len(all_uids)}ëª…\")\n",
    "    print(f\"âœ… ì´ë¯¸ ë§ˆìŠ¤í¬ê°€ ìˆëŠ” í™˜ì: {len(all_uids) - len(missing_uids)}ëª…\")\n",
    "    print(f\"ğŸ”¥ ìƒˆë¡œ ë§Œë“¤ì–´ì•¼ í•  í™˜ì: {len(missing_uids)}ëª…\")\n",
    "    \n",
    "    if len(missing_uids) == 0:\n",
    "        print(\"ğŸ‰ ëª¨ë“  í™˜ìì˜ ë§ˆìŠ¤í¬ê°€ ì´ë¯¸ ì™„ë²½í•˜ê²Œ ì¡´ì¬í•©ë‹ˆë‹¤! ë” ì´ìƒ í•  ì‘ì—…ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "\n",
    "    # ì´ì œ ë¹µê¾¸ë‚œ í™˜ìë“¤ë§Œ ë£¨í”„ë¥¼ ë•ë‹ˆë‹¤.\n",
    "    for uid in tqdm(missing_uids, desc=\"Generating Missing Masks\"):\n",
    "        save_path = os.path.join(MASK_SAVE_ROOT, f\"{uid}.nii.gz\") \n",
    "\n",
    "        try:\n",
    "            dicom_dir = os.path.join(TRAIN_IMAGES_DIR, uid)\n",
    "            dcm_files = [f for f in os.listdir(dicom_dir) if f.endswith('.dcm')] \n",
    "            \n",
    "            if len(dcm_files) == 0:\n",
    "                print(f\"âš ï¸ {uid} í´ë”ì— DICOM íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. (í˜¹ì‹œ ì´ë¯¸ PNGë¡œ ë³€í™˜í•˜ê³  ì§€ìš°ì…¨ë‚˜ìš”?)\")\n",
    "                continue\n",
    "                \n",
    "            dcm_data = []\n",
    "            for f in dcm_files:\n",
    "                ds = pydicom.dcmread(os.path.join(dicom_dir, f))\n",
    "                dcm_data.append({\n",
    "                    'pixel': ds.pixel_array.astype(np.float32) * float(getattr(ds, 'RescaleSlope', 1)) + float(getattr(ds, 'RescaleIntercept', 0)),\n",
    "                    'z_pos': float(ds.ImagePositionPatient[2])\n",
    "                })\n",
    "            \n",
    "            dcm_data.sort(key=lambda x: x['z_pos'], reverse=True)\n",
    "            orig_vol = np.stack([x['pixel'] for x in dcm_data], axis=0)\n",
    "            orig_z, orig_h, orig_w = orig_vol.shape\n",
    "\n",
    "            vol_win = apply_windowing(orig_vol, WL, WW)\n",
    "            input_vol = zoom(vol_win, (TARGET_Z/orig_z, TARGET_SIZE/orig_h, TARGET_SIZE/orig_w), order=1)\n",
    "\n",
    "            ensemble_probs = np.zeros((TARGET_Z, 8, TARGET_SIZE, TARGET_SIZE), dtype=np.float32)\n",
    "\n",
    "            for z in range(TARGET_Z):\n",
    "                img_slice = torch.from_numpy(input_vol[z]).unsqueeze(0)\n",
    "                z_pos = torch.full((1, TARGET_SIZE, TARGET_SIZE), z / (TARGET_Z - 1))\n",
    "                input_tensor = torch.cat([img_slice, z_pos], dim=0).unsqueeze(0).to(DEVICE)\n",
    "\n",
    "                combined_prob = torch.zeros((1, 8, TARGET_SIZE, TARGET_SIZE)).to(DEVICE)\n",
    "                for m in models:\n",
    "                    output = m(input_tensor)\n",
    "                    combined_prob += F.softmax(output, dim=1)\n",
    "                \n",
    "                ensemble_probs[z] = (combined_prob / 5.0).cpu().numpy()[0]\n",
    "\n",
    "            mask_128 = np.argmax(ensemble_probs, axis=1).astype(np.uint8)\n",
    "\n",
    "            full_mask = zoom(mask_128, (orig_z/TARGET_Z, orig_h/TARGET_SIZE, orig_w/TARGET_SIZE), order=0)\n",
    "            full_mask = np.flip(full_mask, axis=(0, 1)) \n",
    "\n",
    "            mask_img = sitk.GetImageFromArray(full_mask)\n",
    "            sitk.WriteImage(mask_img, save_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ {uid} ì²˜ë¦¬ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run_ensemble_factory_fill_missing()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e671d291",
   "metadata": {},
   "source": [
    "## ê°€ì§œ ì •ë‹µì§€ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2f298c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ 1. í™˜ìë³„ ì •ë‹µì§€(train.csv) ë¡œë”© ì¤‘...\n",
      "ğŸ“ ì´ 2019ëª…ì˜ ë§ˆìŠ¤í¬ íŒŒì¼ì„ ë¶„ì„í•©ë‹ˆë‹¤.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ§¬ ìŠ¬ë¼ì´ìŠ¤ë³„ ê°€ì§œ ì •ë‹µ(Weak Label) ìƒì„± ì¤‘: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2019/2019 [07:00<00:00,  4.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ¨ [ì™„ë£Œ] ì•½ì§€ë„ í•™ìŠµ(Weak Labeling)ìš© ë§ˆìŠ¤í„° ì •ë‹µì§€ê°€ ì™„ì„±ë˜ì—ˆìŠµë‹ˆë‹¤!\n",
      "ğŸ“Š ìµœì¢… í™•ë³´ëœ ì•Œì§œë°°ê¸° ë¼ˆ ìŠ¬ë¼ì´ìŠ¤ ê°œìˆ˜: 448,032ì¥\n",
      "ğŸ’¾ ì €ì¥ ê²½ë¡œ: C:\\conda\\3. Project\\rsna-2022-cervical-spine-fracture-detection\\old_train\\pseudo_slice_labels_2019.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>slice_number</th>\n",
       "      <th>present_bones</th>\n",
       "      <th>fracture</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2.826.0.1.3680043.10001</td>\n",
       "      <td>36</td>\n",
       "      <td>C7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.2.826.0.1.3680043.10001</td>\n",
       "      <td>37</td>\n",
       "      <td>C7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2.826.0.1.3680043.10001</td>\n",
       "      <td>40</td>\n",
       "      <td>C7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.2.826.0.1.3680043.10001</td>\n",
       "      <td>41</td>\n",
       "      <td>C7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.2.826.0.1.3680043.10001</td>\n",
       "      <td>42</td>\n",
       "      <td>C7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.2.826.0.1.3680043.10001</td>\n",
       "      <td>43</td>\n",
       "      <td>C7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.2.826.0.1.3680043.10001</td>\n",
       "      <td>44</td>\n",
       "      <td>C7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.2.826.0.1.3680043.10001</td>\n",
       "      <td>45</td>\n",
       "      <td>C7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.2.826.0.1.3680043.10001</td>\n",
       "      <td>46</td>\n",
       "      <td>C7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.2.826.0.1.3680043.10001</td>\n",
       "      <td>47</td>\n",
       "      <td>C7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            StudyInstanceUID  slice_number present_bones  fracture\n",
       "0  1.2.826.0.1.3680043.10001            36            C7         0\n",
       "1  1.2.826.0.1.3680043.10001            37            C7         0\n",
       "2  1.2.826.0.1.3680043.10001            40            C7         0\n",
       "3  1.2.826.0.1.3680043.10001            41            C7         0\n",
       "4  1.2.826.0.1.3680043.10001            42            C7         0\n",
       "5  1.2.826.0.1.3680043.10001            43            C7         0\n",
       "6  1.2.826.0.1.3680043.10001            44            C7         0\n",
       "7  1.2.826.0.1.3680043.10001            45            C7         0\n",
       "8  1.2.826.0.1.3680043.10001            46            C7         0\n",
       "9  1.2.826.0.1.3680043.10001            47            C7         0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- [1. ê²½ë¡œ ì„¤ì •] ---\n",
    "# ì£¼ìµœì¸¡ì´ ì¤€ 2019ëª… ì›ë³¸ ì •ë‹µì§€\n",
    "TRAIN_CSV_PATH = r'C:\\conda\\3. Project\\rsna-2022-cervical-spine-fracture-detection\\old_train\\train.csv'\n",
    "\n",
    "# Step 1ì—ì„œ ìš°ë¦¬ê°€ ë½‘ì•„ë‚¸ 2019ëª… NIfTI ë§ˆìŠ¤í¬ í´ë”\n",
    "MASK_DIR = r'C:\\conda\\3. Project\\rsna-2022-cervical-spine-fracture-detection\\old_train\\pseudo_segmentation_masks_2019'\n",
    "\n",
    "# ğŸ”¥ ìƒˆë¡­ê²Œ íƒ„ìƒí•  60ë§Œ ì¥ì§œë¦¬ ê±°ëŒ€ ê°€ì§œ ì •ë‹µì§€ ì €ì¥ ê²½ë¡œ\n",
    "SAVE_CSV_PATH = r'C:\\conda\\3. Project\\rsna-2022-cervical-spine-fracture-detection\\old_train\\pseudo_slice_labels_2019.csv'\n",
    "\n",
    "print(\"ğŸ”„ 1. í™˜ìë³„ ì •ë‹µì§€(train.csv) ë¡œë”© ì¤‘...\")\n",
    "df_train = pd.read_csv(TRAIN_CSV_PATH)\n",
    "\n",
    "# í™˜ì UIDë¥¼ ë„£ìœ¼ë©´ -> C1~C7 ê³¨ì ˆ ì—¬ë¶€ë¥¼ ë°”ë¡œ ì•Œë ¤ì£¼ëŠ” ì‚¬ì „(Dictionary) ë§Œë“¤ê¸°\n",
    "uid_to_labels = {}\n",
    "for _, row in df_train.iterrows():\n",
    "    uid_to_labels[row['StudyInstanceUID']] = {\n",
    "        1: row['C1'], 2: row['C2'], 3: row['C3'],\n",
    "        4: row['C4'], 5: row['C5'], 6: row['C6'], 7: row['C7']\n",
    "    }\n",
    "\n",
    "nifti_files = [f for f in os.listdir(MASK_DIR) if f.endswith('.nii.gz')]\n",
    "print(f\"ğŸ“ ì´ {len(nifti_files)}ëª…ì˜ ë§ˆìŠ¤í¬ íŒŒì¼ì„ ë¶„ì„í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "results = []\n",
    "\n",
    "# --- [2. ë§ˆìŠ¤í¬ë¥¼ í›‘ìœ¼ë©° ìŠ¬ë¼ì´ìŠ¤ë³„ ì •ë‹µ ìƒì„±] ---\n",
    "for f in tqdm(nifti_files, desc=\"ğŸ§¬ ìŠ¬ë¼ì´ìŠ¤ë³„ ê°€ì§œ ì •ë‹µ(Weak Label) ìƒì„± ì¤‘\"):\n",
    "    uid = f.replace('.nii.gz', '')\n",
    "\n",
    "    # ë§Œì•½ train.csvì— ì—†ëŠ” í™˜ìë©´ íŒ¨ìŠ¤\n",
    "    if uid not in uid_to_labels:\n",
    "        continue\n",
    "\n",
    "    patient_labels = uid_to_labels[uid] # ì´ í™˜ìì˜ ë¼ˆë³„ ê³¨ì ˆ ì •ë‹µ (ì˜ˆ: C4=1, ë‚˜ë¨¸ì§€=0)\n",
    "\n",
    "    # 3D ë§ˆìŠ¤í¬ ë¡œë“œ (SimpleITKë¥¼ ì“°ë©´ Zì¶• ìŠ¬ë¼ì´ìŠ¤ ìˆœì„œê°€ ì™„ë²½í•˜ê²Œ ìœ ì§€ë©ë‹ˆë‹¤)\n",
    "    nifti_path = os.path.join(MASK_DIR, f)\n",
    "    img = sitk.ReadImage(nifti_path)\n",
    "    mask_array = sitk.GetArrayFromImage(img) # í˜•íƒœ: (Z_slices, Height, Width)\n",
    "\n",
    "    num_slices = mask_array.shape[0]\n",
    "\n",
    "    for z in range(num_slices):\n",
    "        slice_mask = mask_array[z]\n",
    "        \n",
    "        # ì´ ìŠ¬ë¼ì´ìŠ¤ ì‚¬ì§„ ì•ˆì— ë„ëŒ€ì²´ ëª‡ ë²ˆ ë¼ˆë“¤ì´ ë“¤ì–´ìˆë‚˜ í™•ì¸\n",
    "        unique_bones = np.unique(slice_mask)\n",
    "        # ë°°ê²½(0)ì´ë‚˜ ì¡ìŒ ë¹¼ê³  ì˜¤ì§ 1ë²ˆ~7ë²ˆ(C1~C7) ë¼ˆë§Œ ë‚¨ê¹€\n",
    "        unique_bones = [b for b in unique_bones if 1 <= b <= 7]\n",
    "\n",
    "        # ğŸ¯ [í•µì‹¬] ë¼ˆê°€ ë‹¨ í•˜ë‚˜ë„ ì•ˆ ì°íŒ ì •ìˆ˜ë¦¬, ê°€ìŠ´íŒ ì‚¬ì§„ì€ í•™ìŠµ ë°ì´í„°ì—ì„œ ì¿¨í•˜ê²Œ ë²„ë¦¼!\n",
    "        if len(unique_bones) == 0:\n",
    "            continue\n",
    "\n",
    "        # ê³¨ì ˆ ì—¬ë¶€ íŒë³„ ë¡œì§\n",
    "        slice_fracture = 0\n",
    "        for bone in unique_bones:\n",
    "            # ì´ ìŠ¬ë¼ì´ìŠ¤ì— ì°íŒ ë¼ˆ ì¤‘ì—, ë‹¨ í•˜ë‚˜ë¼ë„ train.csvì—ì„œ 'ê³¨ì ˆ'ì´ë¼ê³  í•œ ë¼ˆê°€ ìˆë‹¤ë©´?\n",
    "            if patient_labels[bone] == 1:\n",
    "                slice_fracture = 1  # ì´ ìŠ¬ë¼ì´ìŠ¤ëŠ” ë¬´ì¡°ê±´ \"ê³¨ì ˆ(1)\" ë¼ë²¨ ë¶€ì—¬!\n",
    "                break\n",
    "\n",
    "        # ë³´í†µ NIfTI Zì¶• ì¸ë±ìŠ¤(0ë¶€í„°) + 1 = ì›ë³¸ DICOMì˜ ìŠ¬ë¼ì´ìŠ¤ ë²ˆí˜¸(InstanceNumber)\n",
    "        slice_number = z + 1 \n",
    "\n",
    "        # ë‚˜ì¤‘ì— í™•ì¸í•˜ê¸° í¸í•˜ê²Œ \"ì´ ì‚¬ì§„ì—” C2, C3ê°€ ì°í˜€ìˆë‹¤\"ëŠ” ë©”ëª¨ë„ ê°™ì´ ë‚¨ê¹ë‹ˆë‹¤.\n",
    "        bones_str = \"_\".join([f\"C{b}\" for b in unique_bones])\n",
    "\n",
    "        # ê²°ê³¼ ì €ì¥\n",
    "        results.append({\n",
    "            'StudyInstanceUID': uid,\n",
    "            'slice_number': slice_number,\n",
    "            'present_bones': bones_str,\n",
    "            'fracture': slice_fracture\n",
    "        })\n",
    "\n",
    "# --- [3. ê²°ê³¼ë¬¼ CSV ì €ì¥] ---\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results.to_csv(SAVE_CSV_PATH, index=False)\n",
    "\n",
    "print(\"\\nâœ¨ [ì™„ë£Œ] ì•½ì§€ë„ í•™ìŠµ(Weak Labeling)ìš© ë§ˆìŠ¤í„° ì •ë‹µì§€ê°€ ì™„ì„±ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "print(f\"ğŸ“Š ìµœì¢… í™•ë³´ëœ ì•Œì§œë°°ê¸° ë¼ˆ ìŠ¬ë¼ì´ìŠ¤ ê°œìˆ˜: {len(df_results):,}ì¥\")\n",
    "print(f\"ğŸ’¾ ì €ì¥ ê²½ë¡œ: {SAVE_CSV_PATH}\")\n",
    "\n",
    "# ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°\n",
    "display(df_results.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd55759",
   "metadata": {},
   "source": [
    "## dicom -> png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f9b638a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ [DICOM -> PNG ë³€í™˜ê¸° ê°€ë™] ì´ 2019ëª… í™˜ì ì²˜ë¦¬ ì‹œì‘!\n",
      "âš ï¸ ê²½ê³ : ë³€í™˜ì´ ì™„ë£Œëœ .dcm íŒŒì¼ì€ í•˜ë“œë””ìŠ¤í¬ì—ì„œ ì¦‰ì‹œ ì˜êµ¬ ì‚­ì œë©ë‹ˆë‹¤!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "í™˜ì ë‹¨ìœ„ ì²˜ë¦¬ ì¤‘: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2019/2019 [2:17:57<00:00,  4.10s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ¨ [ì‘ì—… ì™„ë£Œ] ëŒ€ì²­ì†Œê°€ ëë‚¬ìŠµë‹ˆë‹¤!\n",
      "   - ğŸ–¼ï¸ ìƒˆë¡­ê²Œ ìƒì„±ëœ PNG: 711,601ì¥\n",
      "   - ğŸ—‘ï¸ ì˜êµ¬ ì‚­ì œëœ DICOM: 711,601ì¥\n",
      "   -> í•˜ë“œë””ìŠ¤í¬ ìš©ëŸ‰ì„ ë‹¤ì‹œ í™•ì¸í•´ ë³´ì„¸ìš”! ì—„ì²­ë‚˜ê²Œ ì¾Œì í•´ì¡Œì„ ê²ë‹ˆë‹¤!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pydicom\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "# ==========================================\n",
    "# [ì„¤ì •] ê²½ë¡œ ë° íŒŒë¼ë¯¸í„°\n",
    "# ==========================================\n",
    "# 2019ëª… í™˜ìì˜ ì›ë³¸ DICOMì´ ë“¤ì–´ìˆëŠ” ìµœìƒìœ„ í´ë”\n",
    "TRAIN_IMAGES_DIR = r'C:\\conda\\3. Project\\rsna-2022-cervical-spine-fracture-detection\\old_train\\train_images'\n",
    "\n",
    "# ë¼ˆë¥¼ ì„ ëª…í•˜ê²Œ ë³´ê¸° ìœ„í•œ Windowing ì„¤ì • (ì ˆëŒ€ ê³ ì •!)\n",
    "WL, WW = 500, 2000\n",
    "\n",
    "# ==========================================\n",
    "# [í•¨ìˆ˜] ìœˆë„ìœ™ ì²˜ë¦¬\n",
    "# ==========================================\n",
    "def apply_windowing(img, wl, ww):\n",
    "    img_min, img_max = wl - ww // 2, wl + ww // 2\n",
    "    img = np.clip(img, img_min, img_max)\n",
    "    # 0.0 ~ 1.0 ì‚¬ì´ì˜ float ê°’ìœ¼ë¡œ ë°˜í™˜\n",
    "    return ((img - img_min) / ww).astype(np.float32)\n",
    "\n",
    "def get_slice_number(filename):\n",
    "    match = re.search(r'\\d+', filename)\n",
    "    return int(match.group()) if match else -1\n",
    "\n",
    "# ==========================================\n",
    "# [ë©”ì¸] ì¼ê´„ ë³€í™˜ ë° ì¦‰ì‹œ ì‚­ì œ ë¡œì§\n",
    "# ==========================================\n",
    "def convert_and_destroy():\n",
    "    if not os.path.exists(TRAIN_IMAGES_DIR):\n",
    "        print(f\"âŒ ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {TRAIN_IMAGES_DIR}\")\n",
    "        return\n",
    "\n",
    "    uids = [d for d in os.listdir(TRAIN_IMAGES_DIR) if os.path.isdir(os.path.join(TRAIN_IMAGES_DIR, d))]\n",
    "    print(f\"ğŸš€ [DICOM -> PNG ë³€í™˜ê¸° ê°€ë™] ì´ {len(uids)}ëª… í™˜ì ì²˜ë¦¬ ì‹œì‘!\")\n",
    "    print(\"âš ï¸ ê²½ê³ : ë³€í™˜ì´ ì™„ë£Œëœ .dcm íŒŒì¼ì€ í•˜ë“œë””ìŠ¤í¬ì—ì„œ ì¦‰ì‹œ ì˜êµ¬ ì‚­ì œë©ë‹ˆë‹¤!\")\n",
    "\n",
    "    # ì„±ê³µ, ì‹¤íŒ¨ ì¹´ìš´íŠ¸\n",
    "    total_converted = 0\n",
    "    total_deleted = 0\n",
    "\n",
    "    for uid in tqdm(uids, desc=\"í™˜ì ë‹¨ìœ„ ì²˜ë¦¬ ì¤‘\"):\n",
    "        patient_dir = os.path.join(TRAIN_IMAGES_DIR, uid)\n",
    "        \n",
    "        # ì´ í™˜ì í´ë” ì•ˆì˜ ëª¨ë“  íŒŒì¼ ê°€ì ¸ì˜¤ê¸°\n",
    "        files = os.listdir(patient_dir)\n",
    "        \n",
    "        # .dcm íŒŒì¼ë§Œ í•„í„°ë§\n",
    "        dcm_files = [f for f in files if f.endswith('.dcm')]\n",
    "        \n",
    "        for dcm_filename in dcm_files:\n",
    "            dcm_path = os.path.join(patient_dir, dcm_filename)\n",
    "            \n",
    "            # ìƒˆë¡­ê²Œ ì €ì¥ë  PNG íŒŒì¼ ì´ë¦„ ì„¤ì • (í™•ì¥ìë§Œ .pngë¡œ ë³€ê²½)\n",
    "            png_filename = dcm_filename.replace('.dcm', '.png')\n",
    "            png_path = os.path.join(patient_dir, png_filename)\n",
    "            \n",
    "            # ì´ë¯¸ ë³€í™˜ëœ PNGê°€ ìˆë‹¤ë©´ êµ³ì´ ë‹¤ì‹œ ì•ˆ ë§Œë“¤ê³  DICOMë§Œ ì§€ì›€ (ì´ì–´í•˜ê¸° ë°©ì–´ ë¡œì§)\n",
    "            if os.path.exists(png_path):\n",
    "                try:\n",
    "                    os.remove(dcm_path)\n",
    "                    total_deleted += 1\n",
    "                except: pass\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # 1. DICOM ì½ê¸°\n",
    "                ds = pydicom.dcmread(dcm_path)\n",
    "                \n",
    "                # 2. í”½ì…€ê°’ ë³µì› (Slope & Intercept ì ìš©)\n",
    "                slope = float(getattr(ds, 'RescaleSlope', 1.0))\n",
    "                intercept = float(getattr(ds, 'RescaleIntercept', 0.0))\n",
    "                px = ds.pixel_array.astype(np.float32) * slope + intercept\n",
    "                \n",
    "                # 3. ë¼ˆ ìœˆë„ìœ™ ì ìš© (0.0 ~ 1.0)\n",
    "                img_float = apply_windowing(px, WL, WW)\n",
    "                \n",
    "                # 4. ì´ë¯¸ì§€ ì €ì¥ì„ ìœ„í•´ 0~255 (uint8) í˜•íƒœë¡œ ë³€í™˜\n",
    "                img_uint8 = (img_float * 255.0).astype(np.uint8)\n",
    "                \n",
    "                # 5. PNG ì €ì¥ (ì••ì¶•ë¥  ìµœëŒ€ë¡œ ê°€ë³ê²Œ!)\n",
    "                success = cv2.imwrite(png_path, img_uint8)\n",
    "                \n",
    "                # 6. ğŸ—‘ï¸ ì €ì¥ì´ ì™„ë²½í•˜ê²Œ ì„±ê³µí–ˆì„ ë•Œë§Œ DICOM ì›ë³¸ íŒŒê¸°!\n",
    "                if success:\n",
    "                    os.remove(dcm_path)\n",
    "                    total_converted += 1\n",
    "                    total_deleted += 1\n",
    "                    \n",
    "            except Exception as e:\n",
    "                # íŒŒì¼ì´ ê¹¨ì¡Œê±°ë‚˜ ë¬¸ì œê°€ ìƒê¸°ë©´ ìŠ¤í‚µ (ì§€ìš°ì§€ ì•ŠìŒ)\n",
    "                print(f\"âŒ ë³€í™˜ ì—ëŸ¬ [{uid} / {dcm_filename}]: {e}\")\n",
    "                continue\n",
    "\n",
    "    print(f\"\\nâœ¨ [ì‘ì—… ì™„ë£Œ] ëŒ€ì²­ì†Œê°€ ëë‚¬ìŠµë‹ˆë‹¤!\")\n",
    "    print(f\"   - ğŸ–¼ï¸ ìƒˆë¡­ê²Œ ìƒì„±ëœ PNG: {total_converted:,}ì¥\")\n",
    "    print(f\"   - ğŸ—‘ï¸ ì˜êµ¬ ì‚­ì œëœ DICOM: {total_deleted:,}ì¥\")\n",
    "    print(f\"   -> í•˜ë“œë””ìŠ¤í¬ ìš©ëŸ‰ì„ ë‹¤ì‹œ í™•ì¸í•´ ë³´ì„¸ìš”! ì—„ì²­ë‚˜ê²Œ ì¾Œì í•´ì¡Œì„ ê²ë‹ˆë‹¤!\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    convert_and_destroy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93797db",
   "metadata": {},
   "source": [
    "## ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c70b2ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“– ê°€ì§œ ì •ë‹µì§€ ë¡œë“œ ì™„ë£Œ: 448,032ì¥ í¬ë¡­ ëŒ€ê¸° ì¤‘\n",
      "ğŸš€ [Speed 3-Channel Crop] 2019ëª… 3ì±„ë„ í¬ë¡­ ì‹œì‘!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2019/2019 [4:15:53<00:00,  7.60s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… [Complete] 2019ëª… 3ì±„ë„ í¬ë¡­ ì™„ë£Œ!\n",
      "   - ì´ ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ìƒì„± ìˆ˜: 447,958ì¥\n",
      "   - ìµœì¢… ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ì €ì¥: C:\\conda\\3. Project\\rsna-2022-cervical-spine-fracture-detection\\old_train\\det_train_manifest_2019_3ch.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import gc\n",
    "\n",
    "# ==========================================\n",
    "# [ì„¤ì •] ê²½ë¡œ ë° íŒŒë¼ë¯¸í„°\n",
    "# ==========================================\n",
    "# ë³€í™˜ëœ PNG íŒŒì¼ë“¤ì´ ìˆëŠ” í´ë”\n",
    "TRAIN_IMAGES_DIR = r'C:\\conda\\3. Project\\rsna-2022-cervical-spine-fracture-detection\\old_train\\train_images'\n",
    "MASK_DIR = r'C:\\conda\\3. Project\\rsna-2022-cervical-spine-fracture-detection\\old_train\\pseudo_segmentation_masks_2019'\n",
    "PSEUDO_CSV_PATH = r'C:\\conda\\3. Project\\rsna-2022-cervical-spine-fracture-detection\\old_train\\pseudo_slice_labels_2019.csv'\n",
    "\n",
    "# ğŸ”¥ 3ì±„ë„ í¬ë¡­ ì´ë¯¸ì§€ê°€ ì €ì¥ë  ìƒˆë¡œìš´ ëª©ì ì§€ (í´ë”ëª… ë³€ê²½)\n",
    "OUTPUT_DIR = r'C:\\conda\\3. Project\\rsna-2022-cervical-spine-fracture-detection\\old_train\\detection_cropped_2019_512_3ch'\n",
    "OUTPUT_MANIFEST_FULL = r'C:\\conda\\3. Project\\rsna-2022-cervical-spine-fracture-detection\\old_train\\det_train_manifest_2019_3ch.csv'\n",
    "\n",
    "TARGET_SIZE = 512\n",
    "MARGIN_RATIO = 0.2 \n",
    "\n",
    "# ==========================================\n",
    "# [í•¨ìˆ˜] ìœ í‹¸ë¦¬í‹°\n",
    "# ==========================================\n",
    "def get_slice_number(filename):\n",
    "    match = re.search(r'\\d+', filename)\n",
    "    return int(match.group()) if match else -1\n",
    "\n",
    "def get_mask_bbox(mask_slice):\n",
    "    rows = np.any(mask_slice > 0, axis=1)\n",
    "    cols = np.any(mask_slice > 0, axis=0)\n",
    "    if not np.any(rows) or not np.any(cols): return None\n",
    "    y_min, y_max = np.where(rows)[0][[0, -1]]\n",
    "    x_min, x_max = np.where(cols)[0][[0, -1]]\n",
    "    return x_min, y_min, x_max, y_max\n",
    "\n",
    "def make_square_box(x1, y1, x2, y2, img_w, img_h, margin=0.2):\n",
    "    w = x2 - x1\n",
    "    h = y2 - y1\n",
    "    cx, cy = x1 + w // 2, y1 + h // 2\n",
    "    max_side = max(w, h)\n",
    "    new_size = int(max_side * (1 + margin))\n",
    "    half_size = new_size // 2\n",
    "    new_x1 = max(0, cx - half_size)\n",
    "    new_y1 = max(0, cy - half_size)\n",
    "    new_x2 = min(img_w, cx + half_size)\n",
    "    new_y2 = min(img_h, cy + half_size)\n",
    "    if new_x2 <= new_x1 or new_y2 <= new_y1: return 0, 0, img_w, img_h\n",
    "    return int(new_x1), int(new_y1), int(new_x2), int(new_y2)\n",
    "\n",
    "# ==========================================\n",
    "# [ë©”ì¸] 3ì±„ë„ ì¾Œì† í¬ë¡­ (ì´ì–´í•˜ê¸° ì™„ë²½ ì§€ì›)\n",
    "# ==========================================\n",
    "def process_png_crop_3ch():\n",
    "    if not os.path.exists(PSEUDO_CSV_PATH):\n",
    "        print(f\"âŒ ê°€ì§œ ì •ë‹µì§€ CSVê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "    \n",
    "    df_pseudo = pd.read_csv(PSEUDO_CSV_PATH)\n",
    "    print(f\"ğŸ“– ê°€ì§œ ì •ë‹µì§€ ë¡œë“œ ì™„ë£Œ: {len(df_pseudo):,}ì¥ í¬ë¡­ ëŒ€ê¸° ì¤‘\")\n",
    "\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    uids_to_process = df_pseudo['StudyInstanceUID'].unique()\n",
    "    new_rows = []\n",
    "    \n",
    "    print(f\"ğŸš€ [Speed 3-Channel Crop] 2019ëª… 3ì±„ë„ í¬ë¡­ ì‹œì‘!\")\n",
    "\n",
    "    for uid in tqdm(uids_to_process):\n",
    "        patient_dir = os.path.join(TRAIN_IMAGES_DIR, uid)\n",
    "        if not os.path.exists(patient_dir): continue \n",
    "\n",
    "        patient_slices = df_pseudo[df_pseudo['StudyInstanceUID'] == uid]\n",
    "        target_slice_numbers = set(patient_slices['slice_number'].values)\n",
    "        \n",
    "        mask_path = os.path.join(MASK_DIR, f\"{uid}.nii.gz\")\n",
    "        patient_save_dir = os.path.join(OUTPUT_DIR, uid)\n",
    "        os.makedirs(patient_save_dir, exist_ok=True)\n",
    "\n",
    "        try:\n",
    "            png_files = [f for f in os.listdir(patient_dir) if f.endswith('.png')]\n",
    "            png_meta = []\n",
    "            for f in png_files:\n",
    "                png_meta.append({\n",
    "                    'full_path': os.path.join(patient_dir, f),\n",
    "                    'slice_number': get_slice_number(f)\n",
    "                })\n",
    "            png_meta.sort(key=lambda x: x['slice_number'])\n",
    "            \n",
    "            target_z_indices = []\n",
    "            for z_idx, meta in enumerate(png_meta):\n",
    "                if meta['slice_number'] in target_slice_numbers:\n",
    "                    target_z_indices.append((z_idx, meta))\n",
    "            \n",
    "            needs_processing = False\n",
    "            for z_idx, meta in target_z_indices:\n",
    "                if not os.path.exists(os.path.join(patient_save_dir, f\"{z_idx:04d}.npz\")):\n",
    "                    needs_processing = True\n",
    "                    break\n",
    "            \n",
    "            if needs_processing:\n",
    "                if not os.path.exists(mask_path): continue \n",
    "                \n",
    "                # 3D ë§ˆìŠ¤í¬ ë¡œë“œ\n",
    "                mask_itk = sitk.ReadImage(mask_path)\n",
    "                mask_vol = sitk.GetArrayFromImage(mask_itk).astype(np.uint8)\n",
    "\n",
    "                # ğŸ”¥ PNG ì´ë¯¸ì§€ê°€ ê°€ë²¼ìš°ë¯€ë¡œ í•œ í™˜ì ì „ì²´ë¥¼ RAMì— í•œ ë²ˆì— ì˜¬ë¦½ë‹ˆë‹¤! (ì†ë„ ê·¹ëŒ€í™”)\n",
    "                full_vol = []\n",
    "                for meta in png_meta:\n",
    "                    img = cv2.imread(meta['full_path'], cv2.IMREAD_GRAYSCALE)\n",
    "                    full_vol.append(img)\n",
    "                full_vol = np.stack(full_vol, axis=0) # (Z, H, W)\n",
    "\n",
    "                for z_idx, meta in target_z_indices:\n",
    "                    save_path = os.path.join(patient_save_dir, f\"{z_idx:04d}.npz\")\n",
    "                    if os.path.exists(save_path): continue \n",
    "\n",
    "                    if z_idx >= len(mask_vol): break\n",
    "                    m_slice = mask_vol[z_idx]\n",
    "                    \n",
    "                    mask_bbox = get_mask_bbox(m_slice)\n",
    "                    if mask_bbox is None: continue\n",
    "                    mx1, my1, mx2, my2 = mask_bbox\n",
    "                    \n",
    "                    ori_h, ori_w = m_slice.shape\n",
    "                    cx1, cy1, cx2, cy2 = make_square_box(mx1, my1, mx2, my2, ori_w, ori_h, MARGIN_RATIO)\n",
    "                    crop_w, crop_h = cx2 - cx1, cy2 - cy1\n",
    "                    if crop_w == 0: continue\n",
    "                    \n",
    "                    # ğŸ¯ [í•µì‹¬] 3ì±„ë„ ë¬¶ê¸° ë¡œì§ ë¶€í™œ!\n",
    "                    z_prev = max(0, z_idx - 1)\n",
    "                    z_next = min(len(full_vol) - 1, z_idx + 1)\n",
    "                    img_3ch = np.stack([full_vol[z_prev], full_vol[z_idx], full_vol[z_next]], axis=0) \n",
    "                    \n",
    "                    # í¬ë¡­ ë° ë¦¬ì‚¬ì´ì¦ˆ\n",
    "                    cropped_3ch = img_3ch[:, cy1:cy2, cx1:cx2]\n",
    "                    cropped_hwc = np.transpose(cropped_3ch, (1, 2, 0)) # OpenCV ë¦¬ì‚¬ì´ì¦ˆë¥¼ ìœ„í•´ HWC ë³€í™˜\n",
    "                    resized_hwc = cv2.resize(cropped_hwc, (TARGET_SIZE, TARGET_SIZE), interpolation=cv2.INTER_LINEAR)\n",
    "                    final_data = np.transpose(resized_hwc, (2, 0, 1)) # ë‹¤ì‹œ íŒŒì´í† ì¹˜ê°€ ì¢‹ì•„í•˜ëŠ” CHW ë³€í™˜\n",
    "                    \n",
    "                    np.savez_compressed(save_path, data=final_data)\n",
    "                \n",
    "                del mask_vol, full_vol\n",
    "                gc.collect()\n",
    "\n",
    "            for z_idx, meta in target_z_indices:\n",
    "                save_path = os.path.join(patient_save_dir, f\"{z_idx:04d}.npz\")\n",
    "                if os.path.exists(save_path):\n",
    "                    current_slice_num = meta['slice_number']\n",
    "                    is_fracture = patient_slices[patient_slices['slice_number'] == current_slice_num]['fracture'].values[0]\n",
    "                    present_bones = patient_slices[patient_slices['slice_number'] == current_slice_num]['present_bones'].values[0]\n",
    "\n",
    "                    new_rows.append({\n",
    "                        'StudyInstanceUID': uid,\n",
    "                        'slice_idx': z_idx,\n",
    "                        'original_slice_number': current_slice_num,\n",
    "                        'file_path': os.path.join('detection_cropped_2019_512_3ch', uid, f\"{z_idx:04d}.npz\"), # í´ë”ëª… ì£¼ì˜!\n",
    "                        'fracture': is_fracture,\n",
    "                        'present_bones': present_bones\n",
    "                    })\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error {uid}: {e}\")\n",
    "            continue\n",
    "\n",
    "    full_df = pd.DataFrame(new_rows)\n",
    "    full_df.to_csv(OUTPUT_MANIFEST_FULL, index=False)\n",
    "    \n",
    "    print(f\"\\nâœ… [Complete] 2019ëª… 3ì±„ë„ í¬ë¡­ ì™„ë£Œ!\")\n",
    "    print(f\"   - ì´ ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ìƒì„± ìˆ˜: {len(full_df):,}ì¥\")\n",
    "    print(f\"   - ìµœì¢… ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ì €ì¥: {OUTPUT_MANIFEST_FULL}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    process_png_crop_3ch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab569f0c",
   "metadata": {},
   "source": [
    "## í•™ìŠµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c463ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ ì „ì²´ ë°ì´í„° í™˜ì ìˆ˜: 2019ëª…\n",
      "ğŸ›¡ï¸ í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ì œì™¸ëœ í™˜ì ìˆ˜ (Golden): 235ëª…\n",
      "ğŸš€ í•™ìŠµ/ê²€ì¦ì— ì‚¬ìš©í•  í™˜ì ìˆ˜: 1784ëª…\n",
      "\n",
      "âš–ï¸ [ë°ì´í„° ë¶„í•  ì™„ë£Œ]\n",
      "  - Train (1:1 ë°¸ëŸ°ìŠ¤): 85260ì¥ (ê³¨ì ˆ 42630 / ì •ìƒ 42630)\n",
      "  - Val (ì‹¤ì œ ë¹„ìœ¨ ìœ ì§€): 82868ì¥ (ê³¨ì ˆ 8957 / ì •ìƒ 73911)\n",
      "ğŸ› ï¸ ëª¨ë¸ ë¹Œë“œ ì¤‘: tf_efficientnetv2_s.in21k_ft_in1k\n",
      "\n",
      "ğŸš€ [Classification Mode] 1784ëª… í™˜ì ê±°ëŒ€ í•™ìŠµ ì‹œì‘! (Model: tf_efficientnetv2_s.in21k_ft_in1k)\n",
      "\n",
      "[Epoch 1/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‰ Train Loss: 0.9908 | ğŸ“ˆ Val Loss: 0.6985\n",
      "ğŸ† AUC: 0.6314 | Acc: 0.5672 | ğŸ”¥ Recall: 0.6260 | ğŸ¯ Prec: 0.1471 | âš–ï¸ F1: 0.2382\n",
      "ğŸ’¾ Best Model ì €ì¥ë¨! (AUC: 0.6314) - ì¹´ìš´í„° ì´ˆê¸°í™” ğŸ”„\n",
      "\n",
      "[Epoch 2/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‰ Train Loss: 0.6709 | ğŸ“ˆ Val Loss: 0.6569\n",
      "ğŸ† AUC: 0.6524 | Acc: 0.5940 | ğŸ”¥ Recall: 0.6442 | ğŸ¯ Prec: 0.1593 | âš–ï¸ F1: 0.2554\n",
      "ğŸ’¾ Best Model ì €ì¥ë¨! (AUC: 0.6524) - ì¹´ìš´í„° ì´ˆê¸°í™” ğŸ”„\n",
      "\n",
      "[Epoch 3/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‰ Train Loss: 0.5553 | ğŸ“ˆ Val Loss: 0.6864\n",
      "ğŸ† AUC: 0.6355 | Acc: 0.6633 | ğŸ”¥ Recall: 0.5088 | ğŸ¯ Prec: 0.1624 | âš–ï¸ F1: 0.2462\n",
      "âš ï¸ ê¸°ë¡ ê°±ì‹  ì‹¤íŒ¨... (Early Stopping ì¹´ìš´í„°: 1/10)\n",
      "\n",
      "[Epoch 4/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5248/5329 [1:45:31<01:48,  1.34s/it, loss=0.7613]  "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import timm  \n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# --- [1. ì‹œìŠ¤í…œ ì—ëŸ¬ ë° ë©ˆì¶¤ ë°©ì§€] ---\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "cv2.setNumThreads(0) \n",
    "\n",
    "# ==========================================\n",
    "# 2. ì„¤ì • (Configuration)\n",
    "# ==========================================\n",
    "CONFIG = {\n",
    "    'base_dir': r'C:\\conda\\3. Project\\rsna-2022-cervical-spine-fracture-detection',\n",
    "    'manifest_path': r'C:\\conda\\3. Project\\rsna-2022-cervical-spine-fracture-detection\\old_train\\det_train_manifest_2019_3ch.csv',\n",
    "    \n",
    "    # ğŸ›¡ï¸ 235ëª… ê²©ë¦¬ìš© Golden Box CSV\n",
    "    'golden_bbox_csv': r'C:\\conda\\3. Project\\rsna-2022-cervical-spine-fracture-detection\\golden_dataset\\filtered_train_bounding_boxes.csv',\n",
    "    \n",
    "    'model_name': 'tf_efficientnetv2_s.in21k_ft_in1k', \n",
    "    'img_size': 512,    \n",
    "    'batch_size': 16,   \n",
    "    'epochs': 50,\n",
    "    'patience': 10,       \n",
    "    'learning_rate': 5e-5, \n",
    "    'weight_decay': 5e-2,  \n",
    "    \n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    'save_dir': './runs/rsna_clf_efficientnet_pseudo_2019'\n",
    "}\n",
    "\n",
    "# ==========================================\n",
    "# 3. ë°ì´í„° ì¦ê°• (Albumentations) - ì˜ë£Œ ì˜ìƒ ìµœì í™” (ìµœì‹  ë²„ì „ ë°˜ì˜)\n",
    "# ==========================================\n",
    "train_transforms = A.Compose([\n",
    "    A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n",
    "    A.HorizontalFlip(p=0.5), \n",
    "    # ShiftScaleRotate ëŒ€ì‹  ìµœì‹  í•¨ìˆ˜ì¸ Affine ì‚¬ìš©\n",
    "    A.Affine(scale=(0.95, 1.05), translate_percent=(-0.05, 0.05), rotate=(-5, 5), p=0.5), \n",
    "    A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.5), \n",
    "    # GaussNoiseì˜ ì˜›ë‚  íŒŒë¼ë¯¸í„°(var_limit) ì œê±°í•˜ê³  ê¸°ë³¸ê°’ ì‚¬ìš©\n",
    "    A.GaussNoise(p=0.2), \n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)), \n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "val_transforms = A.Compose([\n",
    "    A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# ==========================================\n",
    "# 4. ë°ì´í„°ì…‹ (ì´ˆê³ ì† ì •ì  3ì±„ë„ ë¡œë”©)\n",
    "# ==========================================\n",
    "class RSNAClfDataset(Dataset):\n",
    "    def __init__(self, df, base_dir, transforms=None):\n",
    "        self.df = df\n",
    "        self.base_dir = base_dir\n",
    "        self.transforms = transforms\n",
    "        self.clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        # 'old_train' í´ë” ì•ˆì˜ 'detection_cropped_2019_512_3ch' ê²½ë¡œë¥¼ ì •í™•íˆ ì¡ì•„ì¤ë‹ˆë‹¤.\n",
    "        full_path = os.path.join(self.base_dir, 'old_train', row['file_path'])\n",
    "        \n",
    "        # 1. ë§Œë“¤ì–´ë‘” 3ì±„ë„ npz ë‹¨ìˆ¨ì— ë¡œë“œ!\n",
    "        try:\n",
    "            with np.load(full_path) as loaded:\n",
    "                img = loaded['data'].astype(np.float32) # Shape: (3, 512, 512)\n",
    "        except:\n",
    "            img = np.zeros((3, 512, 512), dtype=np.float32)\n",
    "\n",
    "        # 2. ê° ì±„ë„ë³„ë¡œ CLAHE (ëª…ì•” ëŒ€ë¹„ ê·¹ëŒ€í™”) ì ìš©\n",
    "        img_uint8 = (img * 255).astype(np.uint8)\n",
    "        channels = []\n",
    "        for i in range(3):\n",
    "            channels.append(self.clahe.apply(img_uint8[i]))\n",
    "        \n",
    "        # 3. Albumentations ì¦ê°•ì„ ìœ„í•´ HWC í˜•íƒœë¡œ ê²°í•©\n",
    "        img_hwc = np.stack(channels, axis=-1) \n",
    "        \n",
    "        if self.transforms:\n",
    "            augmented = self.transforms(image=img_hwc)\n",
    "            img_tensor = augmented['image']\n",
    "        else:\n",
    "            img_tensor = torch.from_numpy(np.transpose(img_hwc, (2,0,1))).float() / 255.0\n",
    "\n",
    "        label = torch.tensor([float(row['fracture'])], dtype=torch.float32)\n",
    "        return img_tensor, label\n",
    "\n",
    "# ==========================================\n",
    "# 5. ëª¨ë¸ êµ¬ì„±\n",
    "# ==========================================\n",
    "def build_model(model_name, pretrained=True):\n",
    "    print(f\"ğŸ› ï¸ ëª¨ë¸ ë¹Œë“œ ì¤‘: {model_name}\")\n",
    "    model = timm.create_model(\n",
    "        model_name, pretrained=pretrained, in_chans=3, num_classes=1,\n",
    "        drop_rate=0.3, drop_path_rate=0.2 \n",
    "    )\n",
    "    return model\n",
    "\n",
    "# ==========================================\n",
    "# 6. í•™ìŠµ ë° ê²€ì¦ í•¨ìˆ˜\n",
    "# ==========================================\n",
    "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc=\"Training\", leave=False)\n",
    "    for images, labels in pbar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)  \n",
    "        loss = criterion(outputs, labels) \n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        pbar.set_postfix({'loss': f\"{loss.item():.4f}\"})\n",
    "        \n",
    "    return running_loss / len(dataloader)\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc=\"Validating\", leave=False)\n",
    "    for images, labels in pbar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        probs = torch.sigmoid(outputs).cpu().numpy()\n",
    "        targets = labels.cpu().numpy()\n",
    "        \n",
    "        all_preds.extend(probs)\n",
    "        all_targets.extend(targets)\n",
    "        \n",
    "    all_preds = np.array(all_preds).flatten()\n",
    "    all_targets = np.array(all_targets).flatten()\n",
    "    preds_binary = (all_preds >= 0.5).astype(int)\n",
    "    \n",
    "    val_loss = running_loss / len(dataloader)\n",
    "    \n",
    "    try: auc = roc_auc_score(all_targets, all_preds)\n",
    "    except: auc = 0.5 \n",
    "    \n",
    "    acc = accuracy_score(all_targets, preds_binary)\n",
    "    recall = recall_score(all_targets, preds_binary, zero_division=0)\n",
    "    precision = precision_score(all_targets, preds_binary, zero_division=0)\n",
    "    f1 = f1_score(all_targets, preds_binary, zero_division=0)\n",
    "    \n",
    "    return val_loss, auc, acc, recall, precision, f1\n",
    "\n",
    "# ==========================================\n",
    "# 7. ë©”ì¸ ì‹¤í–‰ \n",
    "# ==========================================\n",
    "if __name__ == '__main__':\n",
    "    os.makedirs(CONFIG['save_dir'], exist_ok=True)\n",
    "    \n",
    "    # 1. ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ë¡œë“œ\n",
    "    df_full = pd.read_csv(CONFIG['manifest_path'])\n",
    "    \n",
    "    # 2. ğŸ›¡ï¸ 235ëª…(Golden Test Set) ì™„ë²½ ê²©ë¦¬!\n",
    "    df_golden = pd.read_csv(CONFIG['golden_bbox_csv'])\n",
    "    golden_uids = set(df_golden['StudyInstanceUID'].astype(str).unique())\n",
    "    df_full['StudyInstanceUID'] = df_full['StudyInstanceUID'].astype(str)\n",
    "    \n",
    "    df_train_val = df_full[~df_full['StudyInstanceUID'].isin(golden_uids)].reset_index(drop=True)\n",
    "    \n",
    "    print(f\"ğŸ“¦ ì „ì²´ ë°ì´í„° í™˜ì ìˆ˜: {df_full['StudyInstanceUID'].nunique()}ëª…\")\n",
    "    print(f\"ğŸ›¡ï¸ í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ì œì™¸ëœ í™˜ì ìˆ˜ (Golden): {len(golden_uids)}ëª…\")\n",
    "    print(f\"ğŸš€ í•™ìŠµ/ê²€ì¦ì— ì‚¬ìš©í•  í™˜ì ìˆ˜: {df_train_val['StudyInstanceUID'].nunique()}ëª…\")\n",
    "\n",
    "    # 3. í™˜ì ë‹¨ìœ„ë¡œ 8:2 ìŠ¤í”Œë¦¿ \n",
    "    gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "    train_idx, val_idx = next(gss.split(df_train_val, groups=df_train_val['StudyInstanceUID']))\n",
    "    \n",
    "    train_df = df_train_val.iloc[train_idx].reset_index(drop=True)\n",
    "    val_df = df_train_val.iloc[val_idx].reset_index(drop=True)\n",
    "    \n",
    "    # 4. âš–ï¸ Train ë°ì´í„° 1:1 ê°•ì œ ì–¸ë”ìƒ˜í”Œë§!\n",
    "    pos_df = train_df[train_df['fracture'] == 1]\n",
    "    neg_df = train_df[train_df['fracture'] == 0]\n",
    "    \n",
    "    if len(neg_df) > len(pos_df):\n",
    "        neg_sampled = neg_df.sample(n=len(pos_df), random_state=42)\n",
    "    else:\n",
    "        neg_sampled = neg_df\n",
    "        \n",
    "    train_df_balanced = pd.concat([pos_df, neg_sampled]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    print(\"\\nâš–ï¸ [ë°ì´í„° ë¶„í•  ì™„ë£Œ]\")\n",
    "    print(f\"  - Train (1:1 ë°¸ëŸ°ìŠ¤): {len(train_df_balanced)}ì¥ (ê³¨ì ˆ {len(pos_df)} / ì •ìƒ {len(neg_sampled)})\")\n",
    "    print(f\"  - Val (ì‹¤ì œ ë¹„ìœ¨ ìœ ì§€): {len(val_df)}ì¥ (ê³¨ì ˆ {len(val_df[val_df['fracture']==1])} / ì •ìƒ {len(val_df[val_df['fracture']==0])})\")\n",
    "\n",
    "    # 5. Dataset ë° DataLoader ì¤€ë¹„\n",
    "    train_ds = RSNAClfDataset(train_df_balanced, CONFIG['base_dir'], transforms=train_transforms)\n",
    "    val_ds = RSNAClfDataset(val_df, CONFIG['base_dir'], transforms=val_transforms)\n",
    "    \n",
    "    train_loader = DataLoader(train_ds, batch_size=CONFIG['batch_size'], shuffle=True, num_workers=0, pin_memory=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=CONFIG['batch_size'], shuffle=False, num_workers=0, pin_memory=True)\n",
    "    \n",
    "    device = CONFIG['device']\n",
    "    model = build_model(CONFIG['model_name']).to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=CONFIG['learning_rate'], weight_decay=CONFIG['weight_decay'])\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=CONFIG['epochs'])\n",
    "    \n",
    "    best_auc = 0.0\n",
    "    early_stop_counter = 0 \n",
    "    \n",
    "    history = {\n",
    "        'epoch': [], 'train_loss': [], 'val_loss': [], \n",
    "        'val_auc': [], 'val_acc': [], 'val_recall': [],\n",
    "        'val_precision': [], 'val_f1': []\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nğŸš€ [Classification Mode] 1784ëª… í™˜ì ê±°ëŒ€ í•™ìŠµ ì‹œì‘! (Model: {CONFIG['model_name']})\")\n",
    "    \n",
    "    for epoch in range(1, CONFIG['epochs'] + 1):\n",
    "        print(f\"\\n[Epoch {epoch}/{CONFIG['epochs']}]\")\n",
    "        \n",
    "        train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss, val_auc, val_acc, val_recall, val_precision, val_f1 = validate(model, val_loader, criterion, device)\n",
    "        \n",
    "        scheduler.step() \n",
    "        \n",
    "        print(f\"ğŸ“‰ Train Loss: {train_loss:.4f} | ğŸ“ˆ Val Loss: {val_loss:.4f}\")\n",
    "        print(f\"ğŸ† AUC: {val_auc:.4f} | Acc: {val_acc:.4f} | ğŸ”¥ Recall: {val_recall:.4f} | ğŸ¯ Prec: {val_precision:.4f} | âš–ï¸ F1: {val_f1:.4f}\")\n",
    "        \n",
    "        history['epoch'].append(epoch)\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_auc'].append(val_auc)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['val_recall'].append(val_recall)\n",
    "        history['val_precision'].append(val_precision)\n",
    "        history['val_f1'].append(val_f1)\n",
    "\n",
    "        # ==========================================================\n",
    "        # ğŸ”¥ [ì—¬ê¸° ì¶”ê°€!] ë§¤ ì—í­ë§ˆë‹¤ ì¦‰ì‹œ ì—‘ì…€(CSV) ë®ì–´ì“°ê¸° ì €ì¥ (ìë™ ì €ì¥)\n",
    "        # ==========================================================\n",
    "        history_df = pd.DataFrame(history)\n",
    "        csv_path = os.path.join(CONFIG['save_dir'], \"history_pseudo_2019.csv\")\n",
    "        history_df.to_csv(csv_path, index=False)\n",
    "        # ==========================================================\n",
    "        \n",
    "        if val_auc > best_auc:\n",
    "            best_auc = val_auc\n",
    "            early_stop_counter = 0 \n",
    "            save_path = os.path.join(CONFIG['save_dir'], \"best_efficientnet_pseudo_2019.pth\")\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"ğŸ’¾ Best Model ì €ì¥ë¨! (AUC: {best_auc:.4f}) - ì¹´ìš´í„° ì´ˆê¸°í™” ğŸ”„\")\n",
    "        else:\n",
    "            early_stop_counter += 1 \n",
    "            print(f\"âš ï¸ ê¸°ë¡ ê°±ì‹  ì‹¤íŒ¨... (Early Stopping ì¹´ìš´í„°: {early_stop_counter}/{CONFIG['patience']})\")\n",
    "            \n",
    "            if early_stop_counter >= CONFIG['patience']:\n",
    "                print(f\"\\nğŸš¨ {CONFIG['patience']} ì—í­ ë™ì•ˆ ì„±ëŠ¥ í–¥ìƒì´ ì—†ì–´ í•™ìŠµì„ ì¡°ê¸° ì¢…ë£Œ(Early Stopping) í•©ë‹ˆë‹¤!\")\n",
    "                break \n",
    "                \n",
    "    print(f\"\\nâœ¨ ê±°ëŒ€ ë°ì´í„° í›ˆë ¨ ì™„ë£Œ! ìµœê³  AUC: {best_auc:.4f}\")\n",
    "    \n",
    "\n",
    "    plt.figure(figsize=(15, 5)) \n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(history['epoch'], history['train_loss'], label='Train Loss', marker='o')\n",
    "    plt.plot(history['epoch'], history['val_loss'], label='Val Loss', marker='o')\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(history['epoch'], history['val_auc'], label='Val AUC', marker='o', color='red')\n",
    "    plt.plot(history['epoch'], history['val_acc'], label='Val Acc', marker='o', color='purple')\n",
    "    plt.title('AUC & Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Score')\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(history['epoch'], history['val_recall'], label='Recall', marker='o', color='orange')\n",
    "    plt.plot(history['epoch'], history['val_precision'], label='Precision', marker='o', color='green')\n",
    "    plt.plot(history['epoch'], history['val_f1'], label='F1-Score', marker='o', color='blue')\n",
    "    plt.title('Recall / Prec / F1')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Score')\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "    plot_path = os.path.join(CONFIG['save_dir'], \"learning_curve_pseudo_2019.png\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plot_path, dpi=300)\n",
    "    print(f\"ğŸ“ˆ ê·¸ë˜í”„ ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {plot_path}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f4ba4a",
   "metadata": {},
   "source": [
    "## ì±…ê°ˆí”¼"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_cu13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

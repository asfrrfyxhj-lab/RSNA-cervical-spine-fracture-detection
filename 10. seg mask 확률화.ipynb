{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdcc45de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¦´ 3D NIfTI ë§ˆìŠ¤í¬ í”½ì…€ ì§€ë¶„ìœ¨ ì¶”ì¶œ ì‹œì‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing NIfTI Volumes: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 235/235 [02:29<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ¨ ì™„ë£Œ! NIfTIì—ì„œ ì¶”ì¶œí•œ ë¼ˆ ì§€ë¶„ìœ¨ ë°ì´í„°ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: ./seg_bone_ratios_from_nifti.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import nibabel as nib # ğŸ§  NIfTI íŒŒì¼ì„ ë‹¤ë£¨ê¸° ìœ„í•œ í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "\n",
    "# --- [ì„¤ì •] ---\n",
    "# .nii ë˜ëŠ” .nii.gz íŒŒì¼ë“¤ì´ ëª¨ì—¬ìˆëŠ” í´ë” ê²½ë¡œ\n",
    "MASK_BASE_DIR = r'C:\\conda\\3. Project\\rsna-2022-cervical-spine-fracture-detection\\golden_dataset\\seg_pseudo_masks'\n",
    "SAVE_CSV_PATH = './seg_bone_ratios_from_nifti.csv'\n",
    "\n",
    "results = []\n",
    "\n",
    "print(\"ğŸ¦´ 3D NIfTI ë§ˆìŠ¤í¬ í”½ì…€ ì§€ë¶„ìœ¨ ì¶”ì¶œ ì‹œì‘...\")\n",
    "\n",
    "# í´ë” ì•ˆì˜ NIfTI íŒŒì¼ë“¤ë§Œ ì‹¹ ë‹¤ ê°€ì ¸ì˜¤ê¸°\n",
    "nifti_files = [f for f in os.listdir(MASK_BASE_DIR) if f.endswith('.nii') or f.endswith('.nii.gz')]\n",
    "\n",
    "for nifti_file in tqdm(nifti_files, desc=\"Processing NIfTI Volumes\"):\n",
    "    # íŒŒì¼ëª…ì—ì„œ í™˜ì UID ë½‘ì•„ë‚´ê¸° (ì˜ˆ: '1.2.826.0.1.3680043.10001.nii' -> '1.2.826.0.1.3680043.10001')\n",
    "    uid = nifti_file.replace('.nii.gz', '').replace('.nii', '')\n",
    "    \n",
    "    file_path = os.path.join(MASK_BASE_DIR, nifti_file)\n",
    "    \n",
    "    # 1. NIfTI 3D ë³¼ë¥¨ ë¡œë“œ\n",
    "    img = nib.load(file_path)\n",
    "    mask_3d = img.get_fdata() # ì¼ë°˜ì ìœ¼ë¡œ í˜•íƒœëŠ” (H, W, D) ë˜ëŠ” (W, H, D)\n",
    "    \n",
    "    # RSNA ë°ì´í„°ì˜ ê²½ìš° ì„¸ ë²ˆì§¸ ì°¨ì›(Zì¶•, D)ì´ ìŠ¬ë¼ì´ìŠ¤ ê°œìˆ˜ì…ë‹ˆë‹¤.\n",
    "    num_slices = mask_3d.shape[2] \n",
    "    \n",
    "    # 2. ìŠ¬ë¼ì´ìŠ¤(Zì¶•) ë‹¨ìœ„ë¡œ ê¹€ë°¥ ì°ë“¯ í›‘ìœ¼ë©° ê³„ì‚°\n",
    "    for z in range(num_slices):\n",
    "        slice_mask = mask_3d[:, :, z] # 2D ìŠ¬ë¼ì´ìŠ¤ í•œ ì¥ ë–¼ì–´ë‚´ê¸°\n",
    "        \n",
    "        # í”½ì…€ ê°œìˆ˜ ì„¸ê¸° (C1~C7)\n",
    "        bone_counts = {c: np.sum(slice_mask == c) for c in range(1, 8)}\n",
    "        total_bone_pixels = sum(bone_counts.values())\n",
    "        \n",
    "        # ë¹„ìœ¨(Ratio) ê³„ì‚°\n",
    "        ratios = {f'C{c}_ratio': 0.0 for c in range(1, 8)}\n",
    "        \n",
    "        if total_bone_pixels > 0:\n",
    "            for c in range(1, 8):\n",
    "                ratios[f'C{c}_ratio'] = bone_counts[c] / total_bone_pixels\n",
    "                \n",
    "        # --- [ì¤‘ìš”] ìŠ¬ë¼ì´ìŠ¤ ë²ˆí˜¸ ë§¤ì¹­ ---\n",
    "        # ë³´í†µ ë°°ì—´ì˜ ì¸ë±ìŠ¤(0ë¶€í„° ì‹œì‘)ì— 1ì„ ë”í•˜ë©´ ì›ë³¸ DICOMì˜ InstanceNumber(ìŠ¬ë¼ì´ìŠ¤ ë²ˆí˜¸)ì™€ ì¼ì¹˜í•©ë‹ˆë‹¤.\n",
    "        slice_idx = z + 1 \n",
    "        \n",
    "        # 3. ê²°ê³¼ ê¸°ë¡\n",
    "        row_data = {\n",
    "            'StudyInstanceUID': uid,\n",
    "            'slice_idx': slice_idx,\n",
    "            'total_bone_pixels': total_bone_pixels\n",
    "        }\n",
    "        row_data.update(ratios)\n",
    "        \n",
    "        results.append(row_data)\n",
    "\n",
    "# --- [CSV ì €ì¥] ---\n",
    "df_ratios = pd.DataFrame(results)\n",
    "df_ratios = df_ratios.sort_values(by=['StudyInstanceUID', 'slice_idx']).reset_index(drop=True)\n",
    "df_ratios.to_csv(SAVE_CSV_PATH, index=False)\n",
    "\n",
    "print(f\"\\nâœ¨ ì™„ë£Œ! NIfTIì—ì„œ ì¶”ì¶œí•œ ë¼ˆ ì§€ë¶„ìœ¨ ë°ì´í„°ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {SAVE_CSV_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef34d210",
   "metadata": {},
   "source": [
    "## ìµœì¢… ì„±ëŠ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b310ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°...\n",
      "ğŸ“Š ë¶„ë¥˜ ë°ì´í„°: 10013ì¥ | ë§ˆìŠ¤í¬ ë°ì´í„°: 77724ì¥\n",
      "ğŸ”„ 2. í†±ë‹ˆë°”í€´ ì¡°ë¦½(Merge) ì¤‘...\n",
      "âœ… ë³‘í•© ì„±ê³µ! ë§¤ì¹­ëœ ìŠ¬ë¼ì´ìŠ¤: 10013ì¥\n",
      "\n",
      "ğŸ§  3. í™˜ìë³„ ìµœì¢… ì ìˆ˜(Max Pooling) ê³„ì‚° ì¤‘...\n",
      "âœ¨ ìµœì¢… ì œì¶œ íŒŒì¼ ì €ì¥ ì™„ë£Œ! â” ./final_patient_predictions.csv\n",
      "\n",
      "| StudyInstanceUID          |   patient_overall |       C1 |       C2 |       C3 |        C4 |         C5 |        C6 |          C7 |\n",
      "|:--------------------------|------------------:|---------:|---------:|---------:|----------:|-----------:|----------:|------------:|\n",
      "| 1.2.826.0.1.3680043.11401 |          0.969864 | 0.969864 | 0.825633 | 0.560107 | 0.76769   | 0.853865   | 0.831188  | 0.407861    |\n",
      "| 1.2.826.0.1.3680043.1151  |          0.913589 | 0.913589 | 0.883897 | 0.139199 | 0.625354  | 0.779593   | 0.0996773 | 0.015646    |\n",
      "| 1.2.826.0.1.3680043.1195  |          0.994656 | 0.994656 | 0.667213 | 0.969769 | 0.0256381 | 0.800307   | 0.164653  | 0.00287244  |\n",
      "| 1.2.826.0.1.3680043.11988 |          0.886296 | 0.886296 | 0.849171 | 0.321834 | 0.0242441 | 0.19577    | 0.040992  | 0.000834302 |\n",
      "| 1.2.826.0.1.3680043.12031 |          1        | 1        | 0.139816 | 0.019135 | 0.0257341 | 0.00713818 | 0.0379493 | 0.000539193 |\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "CLF_PREDS_PATH = './runs/rsna_clf_efficientnet/val_full_predictions.csv'\n",
    "SEG_RATIOS_PATH = './seg_bone_ratios_from_nifti.csv'\n",
    "FINAL_SUBMISSION_PATH = './final_patient_predictions.csv'\n",
    "\n",
    "print(\"ğŸ”„ 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°...\")\n",
    "df_clf = pd.read_csv(CLF_PREDS_PATH)\n",
    "df_seg = pd.read_csv(SEG_RATIOS_PATH)\n",
    "\n",
    "# âœ‚ï¸ [í•µì‹¬ í•´ê²°ì±…] ê¼¬ë¦¬í‘œ ì˜ë¼ë‚´ê¸°! ('_mask' ê¸€ìë¥¼ ë¹ˆì¹¸ìœ¼ë¡œ ë°”ê¿ˆ)\n",
    "df_seg['StudyInstanceUID'] = df_seg['StudyInstanceUID'].str.replace('_mask', '', regex=False)\n",
    "\n",
    "# ğŸ›¡ï¸ ë°ì´í„° íƒ€ì… ì™„ë²½ í†µì¼\n",
    "df_clf['StudyInstanceUID'] = df_clf['StudyInstanceUID'].astype(str)\n",
    "df_seg['StudyInstanceUID'] = df_seg['StudyInstanceUID'].astype(str)\n",
    "\n",
    "df_clf['slice_idx'] = df_clf['slice_idx'].astype(int)\n",
    "df_seg['slice_idx'] = df_seg['slice_idx'].astype(int)\n",
    "\n",
    "print(f\"ğŸ“Š ë¶„ë¥˜ ë°ì´í„°: {len(df_clf)}ì¥ | ë§ˆìŠ¤í¬ ë°ì´í„°: {len(df_seg)}ì¥\")\n",
    "\n",
    "print(\"ğŸ”„ 2. í†±ë‹ˆë°”í€´ ì¡°ë¦½(Merge) ì¤‘...\")\n",
    "df_merged = pd.merge(df_clf, df_seg, on=['StudyInstanceUID', 'slice_idx'], how='inner')\n",
    "\n",
    "print(f\"âœ… ë³‘í•© ì„±ê³µ! ë§¤ì¹­ëœ ìŠ¬ë¼ì´ìŠ¤: {len(df_merged)}ì¥\\n\")\n",
    "\n",
    "if len(df_merged) == 0:\n",
    "    print(\"ğŸš¨ ì•„ì§ë„ 0ì¥ì´ë¼ë©´ 'slice_idx' ëŒ€ì‹  'original_slice_number'ë¡œ í•©ì³ì•¼ í•©ë‹ˆë‹¤.\")\n",
    "else:\n",
    "    # 3. ë§ˆë²•ì˜ ê³„ì‚°: í™•ë¥  Ã— ë¹„ìœ¨\n",
    "    for c in range(1, 8):\n",
    "        df_merged[f'C{c}_fracture_score'] = df_merged['pred_prob'] * df_merged[f'C{c}_ratio']\n",
    "\n",
    "    # 4. í™˜ìë³„ ìµœì¢… ê²°ë¡  ë‚´ë¦¬ê¸° (Max Pooling)\n",
    "    print(\"ğŸ§  3. í™˜ìë³„ ìµœì¢… ì ìˆ˜(Max Pooling) ê³„ì‚° ì¤‘...\")\n",
    "    aggregation_dict = {f'C{c}_fracture_score': 'max' for c in range(1, 8)}\n",
    "    df_patient = df_merged.groupby('StudyInstanceUID').agg(aggregation_dict).reset_index()\n",
    "\n",
    "    df_patient = df_patient.rename(columns={\n",
    "        'C1_fracture_score': 'C1', 'C2_fracture_score': 'C2',\n",
    "        'C3_fracture_score': 'C3', 'C4_fracture_score': 'C4',\n",
    "        'C5_fracture_score': 'C5', 'C6_fracture_score': 'C6', 'C7_fracture_score': 'C7',\n",
    "    })\n",
    "\n",
    "    # ì „ì²´ í™˜ì ê³¨ì ˆ í™•ë¥  ë„ì¶œ (ë¼ˆ ì ìˆ˜ ì¤‘ ìµœê³ ì )\n",
    "    df_patient['patient_overall'] = df_patient[['C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7']].max(axis=1)\n",
    "    df_patient = df_patient[['StudyInstanceUID', 'patient_overall', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7']]\n",
    "\n",
    "    # 5. ì €ì¥ ë° ì¶œë ¥\n",
    "    df_patient.to_csv(FINAL_SUBMISSION_PATH, index=False)\n",
    "    print(f\"âœ¨ ìµœì¢… ì œì¶œ íŒŒì¼ ì €ì¥ ì™„ë£Œ! â” {FINAL_SUBMISSION_PATH}\\n\")\n",
    "    \n",
    "    # ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸° ì¶œë ¥\n",
    "    print(df_patient.head().to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af41356f",
   "metadata": {},
   "source": [
    "## ìµœì¢… ì ìˆ˜ ê³„ì‚°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f0643a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'C1'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\smc\\anaconda3\\envs\\torch_cu13\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'C1'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 49\u001b[39m\n\u001b[32m     46\u001b[39m gt_df = pd.read_csv(GT_PATH)\n\u001b[32m     48\u001b[39m \u001b[38;5;66;03m# ìºê¸€ ì ìˆ˜ ê³„ì‚°\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m kaggle_score = \u001b[43mcompute_rsna_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgt_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mğŸ¥ ë‘êµ¬ë‘êµ¬ë‘êµ¬...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     52\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mğŸ”¥ ë‚˜ì˜ ê°€ìƒ ìºê¸€ ì ìˆ˜ (Log Loss): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkaggle_score\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mcompute_rsna_loss\u001b[39m\u001b[34m(pred_df, gt_df)\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# 8ê°œì˜ í•­ëª©(C1~C7, overall)ì— ëŒ€í•´ ê°ê° Loss ê³„ì‚°\u001b[39;00m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m col, w \u001b[38;5;129;01min\u001b[39;00m weights.items():\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m     y_true = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m.values\n\u001b[32m     29\u001b[39m     \u001b[38;5;66;03m# ìš°ë¦¬ê°€ ë§Œë“  ì˜ˆì¸¡ê°’ ê¸°ë‘¥ ì´ë¦„ì€ col ê·¸ëŒ€ë¡œ (ì˜ˆ: 'C1')\u001b[39;00m\n\u001b[32m     30\u001b[39m     y_pred = df[col].values \n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\smc\\anaconda3\\envs\\torch_cu13\\Lib\\site-packages\\pandas\\core\\frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4115\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\smc\\anaconda3\\envs\\torch_cu13\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'C1'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- [1. íŒŒì¼ ê²½ë¡œ ì„¤ì •] ---\n",
    "# ë°©ê¸ˆ ì‚¬ìš©ìë‹˜ì´ ë§Œë“œì‹  ì˜ˆì¸¡ ê²°ê³¼ íŒŒì¼\n",
    "PRED_PATH = 'final_patient_predictions.csv' \n",
    "# RSNA ëŒ€íšŒì—ì„œ ë‹¤ìš´ë°›ì•˜ë˜ ì›ë³¸ ì •ë‹µì§€ íŒŒì¼\n",
    "GT_PATH = r'C:\\conda\\3. Project\\rsna-2022-cervical-spine-fracture-detection\\golden_dataset\\filtered_train.csv' \n",
    "\n",
    "def compute_rsna_loss(pred_df, gt_df):\n",
    "    # ì˜ˆì¸¡í•œ í™˜ìë“¤ë§Œ ì •ë‹µì§€ì—ì„œ êµì§‘í•©ìœ¼ë¡œ ë½‘ì•„ì˜¤ê¸°\n",
    "    df = pd.merge(pred_df, gt_df, on='StudyInstanceUID', how='inner', suffixes=('_pred', '_gt'))\n",
    "    \n",
    "    # ìºê¸€ ì±„ì  ê¸°ì¤€ (ê°€ì¤‘ì¹˜)\n",
    "    weights = {\n",
    "        'C1': 1, 'C2': 1, 'C3': 1, 'C4': 1, 'C5': 1, 'C6': 1, 'C7': 1,\n",
    "        'patient_overall': 7  # ì „ì²´ ê³¨ì ˆ ì—¬ë¶€ê°€ 7ë°° ì¤‘ìš”!\n",
    "    }\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    total_weight = 0.0\n",
    "    \n",
    "    # ê·¹ë‹¨ì ì¸ í™•ë¥ ê°’(1.0 ë˜ëŠ” 0.0)ì´ ë“¤ì–´ê°€ë©´ ë¡œê·¸(log) ê³„ì‚° ì‹œ ì—ëŸ¬ê°€ ë‚˜ë¯€ë¡œ, ì‚´ì§ ê¹ì•„ì¤ë‹ˆë‹¤ (Clip)\n",
    "    eps = 1e-15\n",
    "    \n",
    "    # 8ê°œì˜ í•­ëª©(C1~C7, overall)ì— ëŒ€í•´ ê°ê° Loss ê³„ì‚°\n",
    "    for col, w in weights.items():\n",
    "        y_true = df[col].values\n",
    "        # ìš°ë¦¬ê°€ ë§Œë“  ì˜ˆì¸¡ê°’ ê¸°ë‘¥ ì´ë¦„ì€ col ê·¸ëŒ€ë¡œ (ì˜ˆ: 'C1')\n",
    "        y_pred = df[col].values \n",
    "        \n",
    "        # 0ê³¼ 1 ì‚¬ì´ë¡œ ì•ˆì „í•˜ê²Œ ê°€ë‘ê¸°\n",
    "        y_pred = np.clip(y_pred, eps, 1 - eps)\n",
    "        \n",
    "        # Log Loss ê³µì‹\n",
    "        loss = - w * (y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "        \n",
    "        total_loss += loss.sum()\n",
    "        total_weight += w * len(df)\n",
    "        \n",
    "    final_score = total_loss / total_weight\n",
    "    return final_score\n",
    "\n",
    "# --- [2. ì±„ì  ì‹¤í–‰!] ---\n",
    "pred_df = pd.read_csv(PRED_PATH)\n",
    "gt_df = pd.read_csv(GT_PATH)\n",
    "\n",
    "# ìºê¸€ ì ìˆ˜ ê³„ì‚°\n",
    "kaggle_score = compute_rsna_loss(pred_df, gt_df)\n",
    "\n",
    "print(\"ğŸ¥ ë‘êµ¬ë‘êµ¬ë‘êµ¬...\")\n",
    "print(f\"ğŸ”¥ ë‚˜ì˜ ê°€ìƒ ìºê¸€ ì ìˆ˜ (Log Loss): {kaggle_score:.4f}\")\n",
    "print(\"(ì ìˆ˜ëŠ” ë‚®ì„ìˆ˜ë¡(0ì— ê°€ê¹Œìš¸ìˆ˜ë¡) ì¢‹ìŠµë‹ˆë‹¤!)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_cu13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

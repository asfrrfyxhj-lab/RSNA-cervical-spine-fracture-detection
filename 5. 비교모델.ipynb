{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7cf2251",
   "metadata": {},
   "source": [
    "## ë¹„êµëª¨ë¸ í•™ìŠµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0fdf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import timm  \n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# --- [ì‹œìŠ¤í…œ ì„¤ì •] ---\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "cv2.setNumThreads(0) \n",
    "torch.backends.cudnn.benchmark = True # âš¡ ê³ ì† í•™ìŠµ ì¹˜íŠ¸í‚¤\n",
    "\n",
    "# ==========================================\n",
    "# 1. ì„¤ì • ë° ê²½ë¡œ (ë‹¤ì¤‘ ë¼ë²¨ ë² ì´ìŠ¤ë¼ì¸ ëª¨ë“œ)\n",
    "# ==========================================\n",
    "CONFIG = {\n",
    "    'base_dir': r'C:\\conda\\3. Project\\rsna-2022-cervical-spine-fracture-detection',\n",
    "    \n",
    "    # 1. 3ì±„ë„ íŒŒì¼ ê²½ë¡œ (ê°€ì§œ ì •ë‹µì§€ í¬í•¨ë¨ âŒ -> ê²½ë¡œë§Œ ì”ë‹ˆë‹¤)\n",
    "    'manifest_path': r'C:\\conda\\3. Project\\rsna-2022-cervical-spine-fracture-detection\\old_train\\det_train_manifest_2019_3ch.csv',\n",
    "    \n",
    "    # 2. ì˜ì‚¬ê°€ ì¹œ BBox ê¸°ë°˜ì˜ ì§„ì§œ ì •ë‹µì§€ (ì‚¬ìš©ìë‹˜ íŒŒì¼ â­• -> fracture ì •ë‹µë§Œ ì”ë‹ˆë‹¤)\n",
    "    'true_label_csv': r'C:\\conda\\3. Project\\rsna-2022-cervical-spine-fracture-detection\\golden_dataset\\det_train_manifest_cropped_full.csv',\n",
    "    \n",
    "    # 3. [ì¶”ê°€] ì£¼ìµœì¸¡ ì›ë³¸ íŒŒì¼ (í™˜ìë³„ C1~C7 ì •ë‹µì´ ìˆëŠ” íŒŒì¼)\n",
    "    'train_csv_path': r'C:\\conda\\3. Project\\rsna-2022-cervical-spine-fracture-detection\\old_train\\train.csv',\n",
    "    \n",
    "    'model_name': 'tf_efficientnetv2_s.in21k_ft_in1k', \n",
    "    'img_size': 512,    \n",
    "    'batch_size': 16,      \n",
    "    'epochs': 100,          # ë¹„êµ ëª¨ë¸ì´ë¯€ë¡œ 30ì—í­ ì •ë„ë©´ ì¶©ë¶„í•©ë‹ˆë‹¤.\n",
    "    'patience': 10,       \n",
    "    'learning_rate': 5e-5, \n",
    "    'weight_decay': 5e-2,  \n",
    "    \n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    'save_dir': './runs/rsna_baseline_multilabel' # ğŸ“ ë² ì´ìŠ¤ë¼ì¸ ì „ìš© í´ë”\n",
    "}\n",
    "\n",
    "# (ë°ì´í„° ì¦ê°•ì€ ì´ì „ê³¼ ë™ì¼í•˜ê²Œ ìœ ì§€)\n",
    "train_transforms = A.Compose([\n",
    "    A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n",
    "    A.HorizontalFlip(p=0.5), \n",
    "    A.Affine(scale=(0.9, 1.1), translate_percent=(-0.05, 0.05), rotate=(-10, 10), p=0.5), \n",
    "    A.RandomBrightnessContrast(brightness_limit=0.15, contrast_limit=0.15, p=0.5), \n",
    "    A.GaussNoise(p=0.3),                                                                 \n",
    "    A.CoarseDropout(max_holes=8, max_height=32, max_width=32, fill_value=0, p=0.3), \n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)), \n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "val_transforms = A.Compose([\n",
    "    A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# ==========================================\n",
    "# 2. ë‹¤ì¤‘ ë¼ë²¨ ì „ìš© ë°ì´í„°ì…‹\n",
    "# ==========================================\n",
    "class RSNAMultiLabelDataset(Dataset):\n",
    "    def __init__(self, df, base_dir, transforms=None):\n",
    "        self.df = df\n",
    "        self.base_dir = base_dir\n",
    "        self.transforms = transforms\n",
    "        self.clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        full_path = os.path.join(self.base_dir, 'old_train', row['file_path'])\n",
    "        try:\n",
    "            with np.load(full_path) as loaded:\n",
    "                img = loaded['data'].astype(np.float32) \n",
    "        except:\n",
    "            img = np.zeros((3, 512, 512), dtype=np.float32)\n",
    "\n",
    "        img_uint8 = (img * 255).astype(np.uint8)\n",
    "        channels = [self.clahe.apply(img_uint8[i]) for i in range(3)]\n",
    "        img_hwc = np.stack(channels, axis=-1) \n",
    "        \n",
    "        if self.transforms:\n",
    "            img_tensor = self.transforms(image=img_hwc)['image']\n",
    "        else:\n",
    "            img_tensor = torch.from_numpy(np.transpose(img_hwc, (2,0,1))).float() / 255.0\n",
    "\n",
    "        # ğŸ¯ [í•µì‹¬] 7ê°œì˜ ì •ë‹µì„ í•˜ë‚˜ì˜ ë°°ì—´ë¡œ ë¬¶ì–´ì„œ ë°˜í™˜í•©ë‹ˆë‹¤! (C1, C2, C3, C4, C5, C6, C7)\n",
    "        label = torch.tensor([\n",
    "            float(row['target_C1']), float(row['target_C2']), float(row['target_C3']),\n",
    "            float(row['target_C4']), float(row['target_C5']), float(row['target_C6']),\n",
    "            float(row['target_C7'])\n",
    "        ], dtype=torch.float32)\n",
    "        \n",
    "        return img_tensor, label\n",
    "\n",
    "# ==========================================\n",
    "# 3. í•™ìŠµ ë° ê²€ì¦ í•¨ìˆ˜ (ì¶œë ¥ 7ê°œ)\n",
    "# ==========================================\n",
    "def train_one_epoch(model, dataloader, criterion, optimizer, device, scaler):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc=\"Training\", leave=False)\n",
    "    for images, labels in pbar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        with torch.amp.autocast('cuda'): \n",
    "            outputs = model(images)  \n",
    "            loss = criterion(outputs, labels) # BCEWithLogitsLossê°€ 7ê°œ í´ë˜ìŠ¤ ê°ê° ê³„ì‚°\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        pbar.set_postfix({'loss': f\"{loss.item():.4f}\"})\n",
    "        \n",
    "    return running_loss / len(dataloader)\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc=\"Validating\", leave=False)\n",
    "    for images, labels in pbar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        probs = torch.sigmoid(outputs).cpu().numpy()\n",
    "        targets = labels.cpu().numpy()\n",
    "        \n",
    "        all_preds.append(probs)\n",
    "        all_targets.append(targets)\n",
    "        \n",
    "    all_preds = np.vstack(all_preds)   # Shape: (ì „ì²´ ìŠ¬ë¼ì´ìŠ¤ ìˆ˜, 7)\n",
    "    all_targets = np.vstack(all_targets) # Shape: (ì „ì²´ ìŠ¬ë¼ì´ìŠ¤ ìˆ˜, 7)\n",
    "    \n",
    "    val_loss = running_loss / len(dataloader)\n",
    "    \n",
    "    # 7ê°œ ë¼ˆ ê°ê°ì˜ AUCë¥¼ êµ¬í•œ ë’¤ í‰ê· ì„ ëƒ…ë‹ˆë‹¤ (Macro AUC)\n",
    "    auc_list = []\n",
    "    for c in range(7):\n",
    "        try:\n",
    "            auc = roc_auc_score(all_targets[:, c], all_preds[:, c])\n",
    "            auc_list.append(auc)\n",
    "        except:\n",
    "            pass # í•´ë‹¹ ë¼ˆì— ê³¨ì ˆ í™˜ìê°€ ê²€ì¦ì…‹ì— ì•„ì˜ˆ ì—†ëŠ” ê²½ìš° ì—ëŸ¬ ë°©ì§€\n",
    "            \n",
    "    mean_auc = np.mean(auc_list) if len(auc_list) > 0 else 0.5\n",
    "    \n",
    "    return val_loss, mean_auc\n",
    "\n",
    "# ==========================================\n",
    "# 4. ë©”ì¸ ì‹¤í–‰ (ë°ì´í„° ë§ˆë²• ì¡°ë¦½)\n",
    "# ==========================================\n",
    "if __name__ == '__main__':\n",
    "    os.makedirs(CONFIG['save_dir'], exist_ok=True)\n",
    "    device = CONFIG['device']\n",
    "    \n",
    "    print(\"ğŸ“– ë°ì´í„° ë¡œë“œ ë° '7 ë‹¤ì¤‘ ë¼ë²¨' ê²°í•© ì¤‘...\")\n",
    "    \n",
    "    df_3ch = pd.read_csv(CONFIG['manifest_path']) \n",
    "    df_true = pd.read_csv(CONFIG['true_label_csv'])\n",
    "    df_train = pd.read_csv(CONFIG['train_csv_path']) # ì£¼ìµœì¸¡ ì›ë³¸ (í™˜ìë³„ C1~C7)\n",
    "    \n",
    "    df_3ch['StudyInstanceUID'] = df_3ch['StudyInstanceUID'].astype(str)\n",
    "    df_true['StudyInstanceUID'] = df_true['StudyInstanceUID'].astype(str)\n",
    "    df_train['StudyInstanceUID'] = df_train['StudyInstanceUID'].astype(str)\n",
    "    \n",
    "    # [1ë‹¨ê³„] ì§„ì§œ ì •ë‹µ + 3ì±„ë„ ê²½ë¡œ í•©ì²´ (235ëª… ì •ì˜ˆ)\n",
    "    df_merged = pd.merge(\n",
    "        df_3ch[['StudyInstanceUID', 'original_slice_number', 'file_path']], \n",
    "        df_true[['StudyInstanceUID', 'original_slice_number', 'fracture']], \n",
    "        on=['StudyInstanceUID', 'original_slice_number'], \n",
    "        how='inner'\n",
    "    )\n",
    "    \n",
    "    # [2ë‹¨ê³„] í™˜ìë³„ C1~C7 ë¼ë²¨ í•©ì²´\n",
    "    df_merged = pd.merge(\n",
    "        df_merged,\n",
    "        df_train[['StudyInstanceUID', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7']],\n",
    "        on='StudyInstanceUID',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # [3ë‹¨ê³„] ë§ˆë²•ì˜ ìˆ˜ì‹: ìŠ¬ë¼ì´ìŠ¤ ê³¨ì ˆ ì—¬ë¶€(fracture)ì— í™˜ì ì •ë‹µ(C1~C7)ì„ ê³±í•´ì¤ë‹ˆë‹¤!\n",
    "    for c in range(1, 8):\n",
    "        df_merged[f'target_C{c}'] = df_merged[f'C{c}'] * df_merged['fracture']\n",
    "        \n",
    "    df_235 = df_merged.reset_index(drop=True)\n",
    "    print(f\"âœ… ë‹¤ì¤‘ ë¼ë²¨(C1~C7) ì •ì˜ˆ ë°ì´í„° ê²°í•© ì™„ë£Œ! (ì´ {len(df_235):,}ì¥)\")\n",
    "\n",
    "    # ğŸ¯ í™˜ì ê¸°ì¤€ìœ¼ë¡œ Train(80%) / Val(20%) ë¶„í• \n",
    "    gss = GroupShuffleSplit(n_splits=1, train_size=0.8, random_state=42)\n",
    "    train_idx, val_idx = next(gss.split(df_235, groups=df_235['StudyInstanceUID']))\n",
    "    \n",
    "    train_df = df_235.iloc[train_idx].reset_index(drop=True)\n",
    "    val_df = df_235.iloc[val_idx].reset_index(drop=True)\n",
    "    \n",
    "    # ğŸ¯ Train ë°ì´í„° 1:1 ë°¸ëŸ°ì‹±\n",
    "    train_frac = train_df[train_df['fracture'] == 1]\n",
    "    train_norm = train_df[train_df['fracture'] == 0].sample(n=len(train_frac), random_state=42)\n",
    "    train_df_balanced = pd.concat([train_frac, train_norm]).sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(\"âš–ï¸ [ë°ì´í„° ë¶„í•  ì™„ë£Œ]\")\n",
    "    print(f\"  - Train (1:1 ê°•ì œ) : {len(train_df_balanced):,}ì¥\")\n",
    "    print(f\"  - Val (ì „ì²´ ìŠ¬ë¼ì´ìŠ¤): {len(val_df):,}ì¥\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    train_ds = RSNAMultiLabelDataset(train_df_balanced, CONFIG['base_dir'], transforms=train_transforms)\n",
    "    val_ds = RSNAMultiLabelDataset(val_df, CONFIG['base_dir'], transforms=val_transforms)\n",
    "    \n",
    "    train_loader = DataLoader(train_ds, batch_size=CONFIG['batch_size'], shuffle=True, num_workers=0, pin_memory=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=CONFIG['batch_size'], shuffle=False, num_workers=0, pin_memory=True)\n",
    "    \n",
    "    # ğŸ› ï¸ ëª¨ë¸ì˜ ì¶œë ¥ì„ 1 â” 7 ë¡œ ë³€ê²½ (num_classes=7)\n",
    "    model = timm.create_model(CONFIG['model_name'], pretrained=True, in_chans=3, num_classes=7).to(device)\n",
    "    \n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=CONFIG['learning_rate'], weight_decay=CONFIG['weight_decay'])\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=CONFIG['epochs'])\n",
    "    scaler = torch.amp.GradScaler('cuda') \n",
    "    \n",
    "    best_auc = 0.0\n",
    "    \n",
    "    print(f\"\\nğŸš€ [Baseline 7-Class] í›ˆë ¨ ì‹œì‘! (Model: {CONFIG['model_name']})\")\n",
    "    \n",
    "    for epoch in range(1, CONFIG['epochs'] + 1):\n",
    "        print(f\"\\n[Epoch {epoch}/{CONFIG['epochs']}]\")\n",
    "        \n",
    "        train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device, scaler)\n",
    "        val_loss, val_auc = validate(model, val_loader, criterion, device)\n",
    "        scheduler.step() \n",
    "        \n",
    "        print(f\"ğŸ“‰ Train Loss: {train_loss:.4f} | ğŸ“ˆ Val Loss: {val_loss:.4f} | ğŸ† Val Mean AUC: {val_auc:.4f}\")\n",
    "        \n",
    "        if val_auc > best_auc:\n",
    "            best_auc = val_auc\n",
    "            save_path = os.path.join(CONFIG['save_dir'], \"best_baseline_multilabel.pth\")\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"ğŸ’¾ Best Model ì €ì¥ë¨! (Mean AUC: {best_auc:.4f}) ğŸ”„\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93a4056",
   "metadata": {},
   "source": [
    "## í•™ìŠµ í‰ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5988faa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import timm\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import random\n",
    "\n",
    "# --- [1. ì„¤ì •] ---\n",
    "CONFIG = {\n",
    "    'base_dir': r'C:\\conda\\3. Project\\rsna-2022-cervical-spine-fracture-detection',\n",
    "    'manifest_path': r'C:\\conda\\3. Project\\rsna-2022-cervical-spine-fracture-detection\\old_train\\det_train_manifest_2019_3ch.csv',\n",
    "    'true_label_csv': r'C:\\conda\\3. Project\\rsna-2022-cervical-spine-fracture-detection\\golden_dataset\\det_train_manifest_cropped_full.csv',\n",
    "    \n",
    "    'model_name': 'tf_efficientnetv2_s.in21k_ft_in1k', \n",
    "    'img_size': 512,\n",
    "    \n",
    "    # ğŸ¯ í•™ìŠµ ì™„ë£Œëœ ë² ì´ìŠ¤ë¼ì¸ ê°€ì¤‘ì¹˜ ê²½ë¡œ\n",
    "    'weights_path': './runs/rsna_baseline_multilabel/best_baseline_multilabel.pth', \n",
    "    \n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    'num_samples': 8\n",
    "}\n",
    "\n",
    "val_transforms = A.Compose([\n",
    "    A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# (ë°ì´í„° ë¡œë”ëŠ” ìœ„ì™€ ë™ì¼)\n",
    "class RSNATestDataset(Dataset):\n",
    "    def __init__(self, df, base_dir, transforms=None):\n",
    "        self.df = df\n",
    "        self.base_dir = base_dir\n",
    "        self.transforms = transforms\n",
    "        self.clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        \n",
    "    def __len__(self): return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        full_path = os.path.join(self.base_dir, 'old_train', row['file_path'])\n",
    "        try:\n",
    "            with np.load(full_path) as loaded: img = loaded['data'].astype(np.float32) \n",
    "        except:\n",
    "            img = np.zeros((3, 512, 512), dtype=np.float32)\n",
    "\n",
    "        img_uint8 = (img * 255).astype(np.uint8)\n",
    "        channels = [self.clahe.apply(img_uint8[i]) for i in range(3)]\n",
    "        img_hwc = np.stack(channels, axis=-1) \n",
    "        \n",
    "        if self.transforms: img_tensor = self.transforms(image=img_hwc)['image']\n",
    "        else: img_tensor = torch.from_numpy(np.transpose(img_hwc, (2,0,1))).float() / 255.0\n",
    "\n",
    "        label = float(row['fracture'])\n",
    "        vis_img = channels[1] \n",
    "        return img_tensor, label, vis_img\n",
    "\n",
    "def visualize_baseline_model():\n",
    "    print(\"ğŸ› ï¸ ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸(7ê°œ ì¶œë ¥) ë°ì´í„° ì¤€ë¹„ ì¤‘...\")\n",
    "    df_3ch = pd.read_csv(CONFIG['manifest_path']) \n",
    "    df_true = pd.read_csv(CONFIG['true_label_csv'])\n",
    "    df_3ch['StudyInstanceUID'] = df_3ch['StudyInstanceUID'].astype(str)\n",
    "    df_true['StudyInstanceUID'] = df_true['StudyInstanceUID'].astype(str)\n",
    "    \n",
    "    df_merged = pd.merge(\n",
    "        df_3ch[['StudyInstanceUID', 'original_slice_number', 'file_path']], \n",
    "        df_true[['StudyInstanceUID', 'original_slice_number', 'fracture']], \n",
    "        on=['StudyInstanceUID', 'original_slice_number'], how='inner'\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    gss = GroupShuffleSplit(n_splits=1, train_size=0.8, random_state=42)\n",
    "    _, val_idx = next(gss.split(df_merged, groups=df_merged['StudyInstanceUID']))\n",
    "    val_df = df_merged.iloc[val_idx].reset_index(drop=True)\n",
    "\n",
    "    sample_df = val_df.sample(n=CONFIG['num_samples'], random_state=random.randint(0, 10000))\n",
    "    test_loader = DataLoader(RSNATestDataset(sample_df, CONFIG['base_dir'], transforms=val_transforms), batch_size=CONFIG['num_samples'], shuffle=False)\n",
    "    \n",
    "    # ğŸš¨ ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ì€ num_classes=7 ì…ë‹ˆë‹¤!\n",
    "    model = timm.create_model(CONFIG['model_name'], pretrained=False, in_chans=3, num_classes=7)\n",
    "    model.load_state_dict(torch.load(CONFIG['weights_path'], map_location=CONFIG['device']))\n",
    "    model.to(CONFIG['device']).eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels, vis_imgs in test_loader:\n",
    "            # ì¶œë ¥ëœ 7ê°œì˜ í™•ë¥ ê°’ì„ ë°›ìŠµë‹ˆë‹¤.\n",
    "            probs = torch.sigmoid(model(images.to(CONFIG['device']))).cpu().numpy()\n",
    "            labels = labels.numpy()\n",
    "            break \n",
    "            \n",
    "    plt.figure(figsize=(16, 8))\n",
    "    for i in range(CONFIG['num_samples']):\n",
    "        plt.subplot(2, 4, i+1)\n",
    "        plt.imshow(vis_imgs[i], cmap='gray')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        true_lbl = int(labels[i])\n",
    "        \n",
    "        # 7ê°œ í™•ë¥  ì¤‘ ê°€ì¥ ë†’ì€ í™•ë¥ (max)ê³¼ ê·¸ ë¼ˆì˜ ì¸ë±ìŠ¤(argmax)ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "        max_prob = np.max(probs[i])\n",
    "        max_idx = np.argmax(probs[i]) + 1 # 0ì¸ë±ìŠ¤ê°€ C1ì´ ë˜ë„ë¡ +1\n",
    "        \n",
    "        pred_lbl = 1 if max_prob >= 0.5 else 0\n",
    "        color = 'green' if true_lbl == pred_lbl else 'red'\n",
    "        \n",
    "        # íƒ€ì´í‹€ì— \"ëª‡ ë²ˆ ë¼ˆ(C)ë¡œ ì˜ˆì¸¡í–ˆëŠ”ì§€\"ë„ ë„ì›Œì¤ë‹ˆë‹¤!\n",
    "        title_text = f\"True: {true_lbl} | Pred: {max_prob:.2f} (C{max_idx})\"\n",
    "        plt.title(title_text, color=color, fontsize=13, fontweight='bold')\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    visualize_baseline_model()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

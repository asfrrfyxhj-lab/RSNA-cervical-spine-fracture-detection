import os
import numpy as np
import torch
from torch.utils.data import Dataset
import albumentations as A
from albumentations.pytorch import ToTensorV2
from tqdm import tqdm



class CervicalDataset(Dataset):
    def __init__(self, patient_list_file, data_dir, transform=None, cache_to_ram=True):
        """
        Args:
            patient_list_file (str): train_patients.txt ë˜ëŠ” val_patients.txt ê²½ë¡œ
            data_dir (str): .npy íŒŒì¼ë“¤ì´ ëª¨ì—¬ìˆëŠ” final_preprocessed í´ë” ê²½ë¡œ
            transform (albumentations): ë°ì´í„° ì¦ê°• í•¨ìˆ˜
            cache_to_ram (bool): ë°ì´í„°ë¥¼ RAMì— ë¯¸ë¦¬ ë‹¤ ì˜¬ë ¤ë‘˜ì§€ ì—¬ë¶€
        """
        with open(patient_list_file, 'r') as f:
            self.patient_ids = [line.strip() for line in f.readlines()]
        
        self.data_dir = data_dir
        self.transform = transform
        self.cache_to_ram = cache_to_ram
        self.num_slices = 128 # ì „ì²˜ë¦¬ ë‹¨ê³„ì—ì„œ ë§ì¶˜ ì¥ìˆ˜
        
        # RAM ìºì‹±ì„ ìœ„í•œ ë”•ì…”ë„ˆë¦¬
        self.image_cache = {}
        self.mask_cache = {}

        if self.cache_to_ram:
            print(f"ğŸ§  {patient_list_file} ë°ì´í„°ë¥¼ RAMì— ë¡œë”© ì¤‘...")
            for pid in tqdm(self.patient_ids):
                img = np.load(os.path.join(data_dir, f"{pid}_img.npy")).astype(np.float32)
                mask = np.load(os.path.join(data_dir, f"{pid}_mask.npy")).astype(np.uint8)
                # â­ [ì—¬ê¸°ì— ì¶”ê°€!] 8ë²ˆ(T1) ì´ìƒì˜ í‰ì¶” ë¼ë²¨ì€ ë°°ê²½(0)ìœ¼ë¡œ ë°€ì–´ë²„ë¦½ë‹ˆë‹¤.
                # ì „ì²˜ë¦¬ì—ì„œ T2ê¹Œì§€ ê°€ì ¸ì˜¤ë”ë¼ë„, í•™ìŠµ ì •ë‹µì§€ëŠ” C1~C7(1~7)ë§Œ ë‚¨ê²Œ ë©ë‹ˆë‹¤.
                mask = np.where(mask > 7, 0, mask)
                
                self.image_cache[pid] = img
                self.mask_cache[pid] = mask
            print(f"âœ… ë¡œë”© ì™„ë£Œ! (í™˜ì ìˆ˜: {len(self.patient_ids)})")

    def __len__(self):
        # ì „ì²´ ë°ì´í„° ê°œìˆ˜ëŠ” 'í™˜ì ìˆ˜ * 128ì¥'ì…ë‹ˆë‹¤.
        return len(self.patient_ids) * self.num_slices

    def __getitem__(self, idx):
        # 1. ì „ì²´ ì¸ë±ìŠ¤ë¥¼ 'í™˜ì ë²ˆí˜¸'ì™€ 'ìŠ¬ë¼ì´ìŠ¤ ë²ˆí˜¸'ë¡œ ë³€í™˜
        patient_idx = idx // self.num_slices
        slice_idx = idx % self.num_slices
        pid = self.patient_ids[patient_idx]

        # 2. ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (ìºì‹œ ë˜ëŠ” ë””ìŠ¤í¬ì—ì„œ)
        if self.cache_to_ram:
            image = self.image_cache[pid][slice_idx] # (224, 224)
            mask = self.mask_cache[pid][slice_idx]   # (224, 224)
        else:
            # ìºì‹± ì•ˆ í•  ê²½ìš° ì—¬ê¸°ì„œ íŒŒì¼ì„ ì§ì ‘ ì½ìŒ (ëŠë¦¼)
            vol = np.load(os.path.join(self.data_dir, f"{pid}_img.npy"))
            image = vol[slice_idx]
            m_vol = np.load(os.path.join(self.data_dir, f"{pid}_mask.npy"))
            mask = m_vol[slice_idx]

        # 3. ë°ì´í„° ì¦ê°• (Augmentation) ì ìš©
        # albumentationsì€ ì´ë¯¸ì§€ì™€ ë§ˆìŠ¤í¬ë¥¼ ë™ì‹œì— ë³€í™˜í•´ì¤ë‹ˆë‹¤.
        if self.transform:
            augmented = self.transform(image=image, mask=mask)
            image = augmented['image']
            mask = augmented['mask']

        # 4. ì‹¤ì‹œê°„ Z-position ì±„ë„ ì¶”ê°€ (0 ~ 1)
        z_pos = slice_idx / (self.num_slices - 1)
        z_channel = np.full(image.shape, z_pos, dtype=np.float32)
        
        # 5. ì±„ë„ ê²°í•© (Image: Ch 0, Z-pos: Ch 1) -> (2, 224, 224)
        if torch.is_tensor(image):
            # ToTensorV2ê°€ ì´ë¯¸ (1, 224, 224)ë¥¼ ë§Œë“¤ì—ˆìœ¼ë¯€ë¡œ
            # ìƒˆë¡œìš´ ì°¨ì›ì„ ë§Œë“œëŠ” stack ëŒ€ì‹ , ê¸°ì¡´ ì±„ë„ ì°¨ì›ì— í•©ì¹˜ëŠ” catì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
            z_tensor = torch.tensor(z_channel) # z_channelë„ (1, 224, 224) í˜•íƒœê°€ ë¨
            image = torch.cat([image, z_tensor], dim=0) # (1+1, 224, 224) -> (2, 224, 224)
        else:
            # ì´ ë¶€ë¶„ì€ transformì´ ì—†ì„ ë•Œ(numpy ìƒíƒœ) ì‹¤í–‰ë¨
            image = np.stack([image, z_channel], axis=0)
            image = torch.from_numpy(image)

        # ë§ˆìŠ¤í¬ë¥¼ Long í…ì„œë¡œ ë³€í™˜ (Loss ê³„ì‚°ìš©)
        if not torch.is_tensor(mask):
            mask = torch.from_numpy(mask).long()

        return image, mask

# --- ë°ì´í„° ì¦ê°•(Augmentation) ì •ì˜ ì˜ˆì‹œ ---
def get_transforms(mode='train'):
    if mode == 'train':
        return A.Compose([
            A.HorizontalFlip(p=0.5),      # 50% í™•ë¥ ë¡œ ì¢Œìš° ë°˜ì „
            A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=15, p=0.5), # ë¯¸ì„¸í•œ íšŒì „/ì´ë™
            A.RandomBrightnessContrast(p=0.2), # ë°ê¸° ì¡°ì ˆ
            # NormalizeëŠ” ëª¨ë¸ì˜ pre-trained ê°€ì¤‘ì¹˜ì— ë”°ë¼ ê²°ì • (ê¸°ë³¸ì€ ToTensorV2)
            ToTensorV2()
        ])
    else:
        # ê²€ì¦(Val) ì‹œì—ëŠ” ì¦ê°• ì—†ì´ í…ì„œ ë³€í™˜ë§Œ
        return A.Compose([
            ToTensorV2()
        ])